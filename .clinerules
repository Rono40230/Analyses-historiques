# R√®gles de Codage Universelles pour Agent IA

## üèóÔ∏è ARCHITECTURE & ORGANISATION (RUST + TAURI)

### üêõ PROTOCOLE DE DEBUGGING POUR L'IA

#### Workflow en Cas d'Erreur de Compilation

```rust
// √âTAPE 1: Lire et Analyser l'Erreur
fn handle_compilation_error(error_message: &str) -> DebugAction {
    // Identifier le type d'erreur
    match error_message {
        msg if msg.contains("cannot borrow") => DebugAction::BorrowCheckerError,
        msg if msg.contains("mismatched types") => DebugAction::TypeMismatch,
        msg if msg.contains("cannot find") => DebugAction::MissingImport,
        msg if msg.contains("trait") && msg.contains("not implemented") => DebugAction::MissingTrait,
        msg if msg.contains("lifetime") => DebugAction::LifetimeError,
        _ => DebugAction::Unknown,
    }
}

// √âTAPE 2: Appliquer le Fix Appropri√©
enum DebugAction {
    BorrowCheckerError,   // ‚Üí Ajouter clone() OU ajuster r√©f√©rences
    TypeMismatch,         // ‚Üí V√©rifier Result<T,E> vs T, ajouter ? ou .await
    MissingImport,        // ‚Üí Ajouter use statement
    MissingTrait,         // ‚Üí Ajouter #[derive(Debug, Clone, ...)]
    LifetimeError,        // ‚Üí Ajuster lifetimes 'a, 'b
    Unknown,              // ‚Üí Lire documentation de l'erreur
}
```

**Erreurs Fr√©quentes et Solutions:**

```rust
// ‚ùå ERREUR 1: Borrow checker
error[E0502]: cannot borrow `x` as mutable because it is also borrowed as immutable

// ‚úÖ SOLUTION A: Clone (si acceptable)
let x_clone = x.clone();
process(&x);
modify(&mut x_clone);

// ‚úÖ SOLUTION B: R√©organiser le code
{
    let result = process(&x);  // borrow immutable
}  // borrow ends here
modify(&mut x);  // maintenant OK

// ‚ùå ERREUR 2: Type mismatch
error[E0308]: mismatched types
  expected `Result<Vec<Price>, ServiceError>`
     found `Vec<Price>`

// ‚úÖ SOLUTION: Wrap dans Ok()
fn fetch_prices() -> Result<Vec<Price>, ServiceError> {
    let prices = vec![/* ... */];
    Ok(prices)  // <-- wrap
}

// ‚ùå ERREUR 3: Await manquant
error[E0308]: mismatched types
  expected `Vec<Price>`
     found `impl Future<Output = Vec<Price>>`

// ‚úÖ SOLUTION: Ajouter .await
let prices = api_client.get_prices().await?;
//                                    ^^^^^^

// ‚ùå ERREUR 4: Trait non impl√©ment√©
error[E0277]: `MyStruct` doesn't implement `Debug`

// ‚úÖ SOLUTION: Ajouter derive
#[derive(Debug)]  // <-- add
pub struct MyStruct { }

// ‚ùå ERREUR 5: Import manquant
error[E0433]: failed to resolve: use of undeclared type `HashMap`

// ‚úÖ SOLUTION: Ajouter import
use std::collections::HashMap;
```

#### Workflow en Cas de Test √âchou√©

```rust
// √âTAPE 1: Lire l'Assertion Failure
// Exemple:
// thread 'tests::test_fetch_prices' panicked at 'assertion failed: `(left == right)`
//   left: `5`,
//  right: `10`', tests/service_test.rs:42:5

// √âTAPE 2: Identifier la Cause
enum TestFailureCause {
    WrongExpectedValue,   // expected != actual
    MockNotConfigured,    // mock retourne None ou panic
    AsyncNotAwaited,      // .await manquant
    SetupIncomplete,      // fixtures mal initialis√©es
}

// √âTAPE 3: Actions de Debug
1. Ajouter println!() ou dbg!() temporairement
   dbg!(&prices);  // voir valeur r√©elle
   
2. V√©rifier les mocks/fixtures
   let mock_data = create_test_data();  // correct?
   
3. Ex√©cuter test individuellement
   cargo test test_fetch_prices -- --nocapture
   
4. Comparer expected vs actual
   assert_eq!(prices.len(), 10);  // expected: 10, actual: 5?
   
5. Fix + cleanup debug code
   // Retirer tous les println!/dbg! avant commit
```

#### Workflow en Cas de Clippy Warning

```bash
# ‚ö†Ô∏è NE JAMAIS IGNORER - TOUJOURS FIX

# Exemple 1: Variable non utilis√©e
warning: unused variable: `data`
  --> src/service.rs:42:9
   |
42 |     let data = fetch_data();
   |         ^^^^ help: consider prefixing with an underscore: `_data`

# ‚úÖ SOLUTIONS:
# A) Utiliser la variable
let data = fetch_data();
process(&data);

# B) Pr√©fixer par _ si vraiment inutilis√©e
let _data = fetch_data();  // intentionnellement inutilis√©

# Exemple 2: Clone inutile
warning: using `clone` on type `Copy`
  --> src/service.rs:55:18
   |
55 |     let x = y.clone();
   |               ^^^^^^^^ help: try dereferencing: `*y`

# ‚úÖ SOLUTION: Supprimer clone
let x = *y;  // Copy trait automatique

# Exemple 3: Comparaison flottante
warning: strict comparison of `f32` or `f64`
  --> src/service.rs:78:8
   |
78 |     if price == 100.0 {
   |        ^^^^^^^^^^^^^^ help: consider using `(price - 100.0).abs() < epsilon`

# ‚úÖ SOLUTION: Utiliser epsilon
const EPSILON: f64 = 1e-10;
if (price - 100.0).abs() < EPSILON {
    // ...
}
```

#### Checklist de Debugging (IA doit suivre)

```markdown
[ ] 1. Lire COMPL√àTEMENT le message d'erreur
[ ] 2. Identifier le TYPE d'erreur (borrow, type, trait, etc.)
[ ] 3. Localiser PR√âCIS√âMENT la ligne concern√©e
[ ] 4. Comprendre le POURQUOI (pas juste appliquer fix aveugl√©ment)
[ ] 5. Appliquer le fix MINIMAL (ne pas sur-corriger)
[ ] 6. Tester avec `cargo check` ou `cargo test`
[ ] 7. V√©rifier qu'aucune NOUVELLE erreur n'appara√Æt
[ ] 8. Cleanup (retirer debug prints, commentaires temporaires)
[ ] 9. Documenter si fix non-√©vident (commentaire explicatif)
```

---

## üèóÔ∏è ARCHITECTURE & ORGANISATION (RUST + TAURI)
Produire du code professionnel, maintenable, performant et conforme aux meilleures pratiques industrielles pour applications natives (Rust + Tauri).

---

## üß† GUIDE DE D√âCISION POUR L'IA (CRITIQUE)

### Quand Appliquer les R√®gles STRICTES (100% Compliance)
```
‚úì Code en production (branches: main, release/*)
‚úì Services critiques: src/services/, src/commands/
‚úì Code expos√© en API publique
‚úì Gestion de donn√©es sensibles (auth, payments, crypto)
‚úì Code partag√© entre modules (src/lib.rs, src/models/)

R√àGLES STRICTES = Toutes les interdictions + Limites de taille + 80% coverage
```

### Quand √™tre FLEXIBLE (Pragmatique)
```
‚úì Prototypes rapides (branches: feature/*, experiment/*)
‚úì Scripts one-off (dossier /scripts, /tools)
‚úì Exemples et documentation (/examples)
‚úì Tests de performance (/benches)
‚úì Premi√®re it√©ration (marquer TODO pour cleanup ult√©rieur)

FLEXIBLE = Autoriser unwrap() temporaire, skip docs, relaxer limites lignes
MAIS: TOUJOURS respecter types Result<>, pas de mock data, pas d'imports circulaires
```

### Arbre de D√©cision Automatique
```rust
fn should_apply_strict_rules(file_path: &str, branch: &str) -> bool {
    // R√®gles strictes par branche
    if branch.starts_with("main") || branch.starts_with("release/") {
        return true;
    }
    
    // R√®gles strictes par chemin
    match file_path {
        path if path.contains("src/services/") => true,
        path if path.contains("src/commands/") => true,
        path if path.contains("src/models/errors.rs") => true,
        path if path.contains("src/lib.rs") => true,
        path if path.contains("src/db/") => true,
        
        // Flexible pour le reste
        path if path.contains("/examples/") => false,
        path if path.contains("/scripts/") => false,
        path if path.contains("/benches/") => false,
        
        // Par d√©faut: strict
        _ => true,
    }
}
```

### Matrice de D√©cision Rapide

| Situation | Action IA | Justification |
|-----------|-----------|---------------|
| Fichier >280 lignes | STOP + Demander plan split | Approche limite (300L) |
| Fichier >350 lignes | REFUS + Split obligatoire | Hard limit d√©pass√© |
| Test √©choue | FIX avant commit | Qualit√© non-n√©gociable |
| Clippy warning | FIX imm√©diatement | Z√©ro tol√©rance |
| Unwrap() dans service | Remplacer par ? ou expect() | S√©curit√© |
| Unwrap() dans test | Acceptable | Contexte de test |
| Mock data d√©tect√© | REJETER + Sugg√©rer API | Principe #6 |
| Import circulaire | BLOQUER + Extraire module | Architecture DAG |
| Clone() excessif (>5/fn) | WARN + Sugg√©rer &ref | Performance |
| Fonction >50 lignes | Sugg√©rer split | Maintenabilit√© |
| Coverage baisse | ALERT + Demander review | Qualit√© r√©gresse |

---

## ‚úÖ CHECKLIST INTERACTIVE PAR T√ÇCHE (IA OBLIGATOIRE)

### Workflow Complet pour Chaque T√¢che

```rust
// L'IA DOIT suivre ce workflow SYST√âMATIQUEMENT

struct TaskWorkflow {
    pre_coding: PreCodingChecklist,
    during_coding: DuringCodingChecklist,
    post_coding: PostCodingChecklist,
}
```

### üìã Phase 1: AVANT de Commencer (Pre-Coding)

```markdown
CHECKLIST PRE-CODING (OBLIGATOIRE):

[ ] 1. COMPRENDRE LA T√ÇCHE
    - Lire COMPL√àTEMENT la demande utilisateur
    - Identifier les fichiers concern√©s
    - Comprendre le contexte m√©tier
    ‚ùå STOP si pas clair ‚Üí Demander clarification

[ ] 2. ANALYSER L'EXISTANT
    - Lire les fichiers qui seront modifi√©s (ENTI√àREMENT, pas juste titre)
    - Identifier les patterns utilis√©s
    - V√©rifier les d√©pendances (imports)
    ‚ùå STOP si architecture DAG viol√©e

[ ] 3. V√âRIFIER LA FAISABILIT√â
    - Estimer taille finale du fichier
    - Calculer: lignes_actuelles + lignes_√†_ajouter
    - Si >280 lignes: WARN
    - Si >300 lignes (services) ou >120 (main): STOP + Demander plan split
    ‚ùå STOP si limite d√©pass√©e

[ ] 4. PLANIFIER LE SPLIT (si n√©cessaire)
    - Identifier responsabilit√©s distinctes
    - Proposer structure des sous-modules
    - Attendre validation utilisateur
    ‚úÖ OK quand plan valid√©

[ ] 5. V√âRIFIER LES D√âPENDANCES
    - S'assurer que les crates n√©cessaires sont dans Cargo.toml
    - V√©rifier les versions compatibles
    - Identifier si nouvelles d√©pendances requises
    ‚ùì Demander si ajout de d√©pendance majeure

[ ] 6. PR√âPARER LES TESTS
    - Identifier les cas de test n√©cessaires
    - Pr√©parer fixtures/mocks si besoin
    - Planifier tests: success, error, edge cases
    ‚úÖ OK quand plan de test clair

üö¶ SI TOUS LES ITEMS ‚úÖ ‚Üí Passer √† la phase coding
üö¶ SI UN SEUL ITEM ‚ùå ‚Üí STOP et r√©soudre avant de coder
```

### üíª Phase 2: PENDANT le Coding (During)

```markdown
CHECKLIST DURING-CODING (VALIDER EN CONTINU):

[ ] 1. TDD - TEST D'ABORD
    - √âcrire le test AVANT l'impl√©mentation
    - Test doit FAIL initialement (red)
    - Impl√©menter le minimum pour passer (green)
    - Refactoriser si n√©cessaire (refactor)
    ‚ö†Ô∏è VIOLATION TDD = Mauvaise pratique

[ ] 2. RESPECTER LES TYPES
    - TOUJOURS utiliser Result<T, ServiceError>
    - JAMAIS unwrap() sans expect() ou ?
    - JAMAIS panic!() dans services/commands
    - TOUJOURS valider inputs
    ‚ùå Violation = Code rejet√©

[ ] 3. ZERO MOCK DATA
    - V√©rifier chaque vec![], HashMap!, etc.
    - Aucune valeur hard-cod√©e (sauf constantes config)
    - Toutes donn√©es depuis API/DB/Cache
    - Gestion explicite des erreurs (pas de fallback silencieux)
    üî¥ CRITIQUE: Violation = Rejet imm√©diat

[ ] 4. DOCUMENTER EN √âCRIVANT
    - Ajouter /// doc comments pour fonctions publiques
    - Expliquer le "pourquoi" dans les commentaires de code
    - Documenter les d√©cisions non-√©videntes
    - Ajouter examples dans la doc si complexe
    ‚úÖ Doc compl√®te avant de passer √† la suite

[ ] 5. V√âRIFIER LA TAILLE TOUS LES 50 LIGNES
    - Compter lignes apr√®s chaque bloc de code
    - Si approche 250+ lignes: RALENTIR
    - Si >280 lignes: STOP + Alerter
    - Si >300 lignes: REFUS + Demander split
    üö® Auto-monitoring obligatoire

[ ] 6. IMPORTS ET VISIBILIT√â
    - Ajouter imports au fur et √† mesure
    - Minimiser pub (seulement ce qui doit √™tre expos√©)
    - Grouper imports (std, crate, external)
    - Supprimer imports inutilis√©s
    ‚úÖ Clean imports √† chaque √©tape

[ ] 7. GESTION D'ERREUR EXPLICITE
    - Chaque Result doit √™tre g√©r√©
    - Utiliser ? pour propagation
    - Convertir erreurs externes (From trait)
    - Logs appropri√©s (error!, warn!, info!)
    ‚ö†Ô∏è Aucune erreur silencieuse tol√©r√©e
```

### üîç Phase 3: APR√àS le Coding (Post-Coding)

```markdown
CHECKLIST POST-CODING (AVANT COMMIT):

[ ] 1. FORMATAGE AUTOMATIQUE
    Action: cargo fmt
    R√©sultat attendu: ‚úÖ Formatting OK
    Si FAIL: Corriger erreurs de syntaxe
    ‚ùå BLOCKER si fail

[ ] 2. LINTING STRICT
    Action: cargo clippy -- -D warnings
    R√©sultat attendu: ‚úÖ 0 warnings
    Si FAIL: Corriger TOUS les warnings
    ‚ùå BLOCKER si warnings restent

[ ] 3. COMPILATION
    Action: cargo build
    R√©sultat attendu: ‚úÖ Compilation success, 0 warnings
    Si FAIL: D√©bugger erreurs (voir protocole debugging)
    ‚ùå BLOCKER si fail

[ ] 4. TESTS UNITAIRES
    Action: cargo test
    R√©sultat attendu: ‚úÖ Tous les tests passent
    Si FAIL: D√©bugger tests √©chou√©s
    ‚ùå BLOCKER si tests fail

[ ] 5. COVERAGE
    Action: cargo tarpaulin (si disponible)
    R√©sultat attendu: ‚úÖ Coverage >80%
    Si FAIL: Ajouter tests manquants
    ‚ö†Ô∏è WARNING si <80%, BLOCKER si <70%

[ ] 6. AUDIT S√âCURIT√â
    Action: cargo audit
    R√©sultat attendu: ‚úÖ 0 vulnerabilities
    Si FAIL: Mettre √† jour d√©pendances vuln√©rables
    üî¥ CRITICAL si vuln√©rabilit√©s high/critical

[ ] 7. V√âRIFIER IMPORTS INUTILIS√âS
    Action: V√©rifier cargo build warnings
    R√©sultat attendu: ‚úÖ Aucun "unused import"
    Si FAIL: Supprimer imports
    ‚úÖ Cleanup obligatoire

[ ] 8. V√âRIFIER CODE MORT
    Action: V√©rifier "dead_code" warnings
    R√©sultat attendu: ‚úÖ Aucune fonction inutilis√©e
    Si FAIL: Supprimer OU ajouter #[allow(dead_code)] avec justification
    ‚ö†Ô∏è Justification requise si allow

[ ] 9. V√âRIFIER TAILLE FINALE
    Action: Compter lignes des fichiers modifi√©s
    R√©sultat attendu: ‚úÖ Tous <300L (ou <120 pour main.rs)
    Si FAIL: Split obligatoire
    ‚ùå BLOCKER si d√©passement

[ ] 10. DOCUMENTATION COMPL√àTE
    Action: V√©rifier /// comments sur fonctions publiques
    R√©sultat attendu: ‚úÖ Toutes fonctions pub document√©es
    Si FAIL: Ajouter documentation manquante
    ‚ö†Ô∏è WARNING mais pas blocker

[ ] 11. GIT DIFF REVIEW
    Action: Relire TOUTES les modifications
    V√©rifier:
      - Pas de debug prints (println!, dbg!)
      - Pas de TODO sans issue
      - Pas de code comment√© >5 lignes
      - Pas de secrets en dur
    ‚úÖ Clean avant commit

[ ] 12. MESSAGE DE COMMIT
    Action: Pr√©parer message conventionnel
    Format: <type>: <description>
    Types: feat, fix, docs, style, refactor, test, chore, perf
    ‚úÖ Message clair et descriptif

üö¶ SI TOUS LES ITEMS ‚úÖ ‚Üí Commit autoris√©
üö¶ SI UN SEUL ITEM ‚ùå BLOCKER ‚Üí INTERDIRE commit
üö¶ SI ITEM ‚ö†Ô∏è WARNING ‚Üí Alerter utilisateur mais autoriser
```

---

## ‚ùì GESTION DES CAS AMBIGUS (IA)

### Quand Demander Clarification √† l'Utilisateur

#### Situations N√âCESSITANT Clarification

```rust
// 1. CHOIX D'ARCHITECTURE MAJEUR
if estimated_lines > 250 && similar_service_exists {
    ask_user(
        "Un service similaire existe d√©j√† (service_x.rs, 180 lignes).\n\
         Options:\n\
         A) √âtendre le service existant (risque: atteindre 430 lignes)\n\
         B) Cr√©er nouveau service s√©par√©\n\
         C) Refactoriser les deux en modules partag√©s\n\
         Quelle option pr√©f√©rez-vous?"
    );
}

// 2. SOURCE DE DONN√âES AMBIGU√ã
if !config.has_api_endpoint("crypto_prices") {
    ask_user(
        "Quelle API utiliser pour les prix crypto?\n\
         - CoinGecko (gratuit, 50 req/min)\n\
         - Binance (n√©cessite API key)\n\
         - CryptoCompare (n√©cessite API key)\n\
         Votre choix?"
    );
}

// 3. BREAKING CHANGE POTENTIEL
if function_is_public && signature_changes && has_external_callers {
    ask_user(
        "ATTENTION: Modifier `fetch_prices()` va casser l'API publique.\n\
         La fonction est utilis√©e dans 5 fichiers.\n\
         Options:\n\
         A) Cr√©er nouvelle fonction + d√©pr√©cier l'ancienne\n\
         B) Modifier + mettre √† jour tous les appels\n\
         C) Annuler la modification\n\
         Votre choix?"
    );
}

// 4. STRAT√âGIE DE MIGRATION
if database_schema_changes {
    ask_user(
        "Changement du sch√©ma DB d√©tect√©.\n\
         Comment g√©rer les donn√©es existantes?\n\
         A) Migration automatique (script SQL)\n\
         B) Supprimer et recr√©er (perte de donn√©es)\n\
         C) Migration manuelle\n\
         Votre choix?"
    );
}

// 5. COMPROMIS PERFORMANCE vs CLART√â
if optimization_reduces_readability {
    ask_user(
        "Optimisation possible: passer de O(n¬≤) √† O(n log n)\n\
         MAIS: code 3x plus complexe (45 lignes vs 15 lignes)\n\
         Gain: ~200ms pour 10k items\n\
         Appliquer l'optimisation?"
    );
}
```

#### D√©cisions AUTOMATIQUES (Ne Pas Demander)

```rust
// 1. FORMATAGE (TOUJOURS rustfmt)
// ‚úÖ D√©cision auto: Appliquer cargo fmt
apply_formatting();

// 2. NOMMAGE (TOUJOURS conventions Rust)
// ‚úÖ D√©cision auto: snake_case pour fonctions
fn fetch_prices() { }  // PAS fetchPrices

// 3. TESTS (TOUJOURS les √©crire)
// ‚úÖ D√©cision auto: G√©n√©rer tests unitaires
generate_tests_for_new_function();

// 4. DOCUMENTATION (TOUJOURS l'ajouter)
// ‚úÖ D√©cision auto: Ajouter doc comments
add_doc_comments();

// 5. GESTION D'ERREUR (TOUJOURS Result<>)
// ‚úÖ D√©cision auto: Utiliser Result au lieu de panic
fn risky_operation() -> Result<Data, ServiceError> { }

// 6. IMPORTS (TOUJOURS group√©s et tri√©s)
// ‚úÖ D√©cision auto: Organiser imports
use std::collections::HashMap;
use crate::models::*;
use external_crate::*;

// 7. VISIBILIT√â (TOUJOURS minimale)
// ‚úÖ D√©cision auto: Fonction interne = priv√©e
fn internal_helper() { }  // PAS pub

// 8. FICHIER TROP GROS (TOUJOURS split)
// ‚úÖ D√©cision auto: Si >300L ‚Üí proposer split
if file_lines > 300 {
    propose_split_plan();  // Ne pas demander SI split, mais COMMENT split
}
```

#### Matrice de D√©cision

| Crit√®re | Demander? | Action IA |
|---------|-----------|-----------|
| Formatage code | ‚ùå Non | Appliquer rustfmt |
| Nommage variable/fonction | ‚ùå Non | Appliquer conventions Rust |
| √âcrire tests | ‚ùå Non | Toujours g√©n√©rer tests |
| Ajouter documentation | ‚ùå Non | Toujours documenter |
| Choix API externe | ‚úÖ Oui | Plusieurs options valides |
| Breaking change | ‚úÖ Oui | Impact sur code existant |
| Architecture majeure | ‚úÖ Oui | D√©cision strat√©gique |
| Optimisation complexe | ‚úÖ Oui | Trade-off perf vs clart√© |
| Migration donn√©es | ‚úÖ Oui | Risque de perte |
| Fonction priv√©e ‚Üí publique | ‚úÖ Oui | √âlargit surface API |
| D√©pendance externe | ‚úÖ Oui | Ajoute complexit√© |
| Refactoring >5 fichiers | ‚úÖ Oui | Impact large |
| Fix typo | ‚ùå Non | Corriger directement |
| Fix clippy warning | ‚ùå Non | Toujours corriger |
| Remplacer unwrap() | ‚ùå Non | Toujours utiliser ? |

### Format de Question √† l'Utilisateur

```rust
// Template de question structur√©e
fn ask_user_structured(context: &str, options: Vec<Option>) -> UserChoice {
    println!("ü§î CLARIFICATION N√âCESSAIRE\n");
    println!("Contexte: {}\n", context);
    println!("Options:");
    for (i, opt) in options.iter().enumerate() {
        println!("  {}. {} - {}", 
            ('A' as u8 + i as u8) as char,
            opt.name,
            opt.description
        );
        if let Some(impact) = &opt.impact {
            println!("     Impact: {}", impact);
        }
        if let Some(risk) = &opt.risk {
            println!("     Risque: {}", risk);
        }
    }
    println!("\nVotre choix? (A/B/C/...)");
    
    // Attendre r√©ponse utilisateur
}

// Exemple d'utilisation
ask_user_structured(
    "D√©tection de service similaire existant",
    vec![
        Option {
            name: "√âtendre existant",
            description: "Ajouter m√©thode au service actuel",
            impact: Some("Fichier passera √† ~280 lignes (acceptable)"),
            risk: Some("Proche de la limite de 300 lignes"),
        },
        Option {
            name: "Cr√©er nouveau",
            description: "Nouveau service avec responsabilit√© claire",
            impact: Some("+ 1 fichier, meilleure s√©paration"),
            risk: Some("Duplication possible si mal con√ßu"),
        },
    ]
);
```

### Timeout et D√©cision par D√©faut

```rust
// Si l'utilisateur ne r√©pond pas (timeout), utiliser option SAFE
const DECISION_TIMEOUT_SECS: u64 = 30;

fn ask_with_timeout(question: &str, default_safe: Action) -> Action {
    match wait_for_response(DECISION_TIMEOUT_SECS) {
        Some(choice) => choice,
        None => {
            warn!("Pas de r√©ponse utilisateur - application de l'option s√ªre");
            default_safe  // Option la plus conservatrice
        }
    }
}

// Exemples d'options "safe":
// - Breaking change? ‚Üí Safe = Cr√©er nouvelle fonction (pas de break)
// - Optimisation? ‚Üí Safe = Garder code clair (pas d'optimisation)
// - Migration? ‚Üí Safe = Ne pas toucher aux donn√©es
// - Architecture? ‚Üí Safe = Minimiser changements
```

---

### Principe 1: DRY (Don't Repeat Yourself)
```
Si tu codes la m√™me chose 2 fois ‚Üí BUG ARCHITECTURALE
D√©tecter et refactoriser IMM√âDIATEMENT

‚ùå MAUVAIS: 3 modules qui g√®rent la m√™me logique m√©tier
‚úÖ BON: 1 module centralis√© avec trait pattern Rust
```

### Principe 2: Single Source of Truth
```
Un concept = UN fichier responsable
Plusieurs fichiers pour la m√™me fonction = dette technique

‚ùå MAUVAIS: data_service.rs + data_fetcher.rs (m√™me responsabilit√©)
‚úÖ BON: data_service.rs centralis√© avec traits et impl√©mentations
```

### Principe 3: Testabilit√© Obligatoire
```
Si tu ne peux pas √©crire un test ‚Üí architecture MAUVAISE
Refactoriser avant de continuer

Test = premi√®re ligne de code (TDD)
Minimum 80% de couverture obligatoire
```

### Principe 4: Clart√© > Flexibilit√©
```
Code clair > Code "flexible" mais incompr√©hensible
Pr√©f√©rer l'explicite √† l'implicite

‚ùå MAUVAIS: .iter().map(...).filter(...).fold(...) sans contexte
‚úÖ BON: calculate_portfolio_value() - clair et testable
```

### Principe 5: Audit Before Feature
```
BUG + Chaos > Nouvelle feature
TOUJOURS auditer avant d'ajouter

Lancer audit mensuellement: cargo audit && cargo clippy
```

### Principe 6: ZERO MOCK DATA - ONLY REAL DATA (CRITIQUE!)

**R√àGLE ABSOLUE - NON N√âGOCIABLE:**
```
‚ùå JAMAIS de donn√©es simul√©es/mocks en production
‚ùå JAMAIS de hardcoded data (sauf constantes config)
‚ùå JAMAIS de fallback dummy values pour production
‚ùå JAMAIS de test data dans le code actif
‚úÖ SEULEMENT donn√©es r√©elles (API, base de donn√©es, fichiers)

VIOLATION = Code rejet√© imm√©diatement
```

**Exemples INTERDITS:**
```rust
// ‚ùå INTERDIT - Mock data
fn get_prices() -> Vec<Price> {
    vec![
        Price { symbol: "BTC", value: 43250.0 },  // Hard-coded!
        Price { symbol: "ETH", value: 2300.0 },   // Mock!
    ]
}

// ‚ùå INTERDIT - Fallback values cachant erreurs
let price = api_response.price.unwrap_or(0.0);  // Si erreur API, affiche 0?
let volume = data.volume.unwrap_or_default();    // Cache les erreurs!
```

**Impl√©mentation CORRECTE:**
```rust
// ‚úÖ BON - Gestion d'erreur explicite avec Result
async fn fetch_prices() -> Result<Vec<Price>, ServiceError> {
    match api_client.get_prices().await {
        Ok(prices) => {
            cache.set("prices", &prices)?;
            Ok(prices)
        }
        Err(e) => {
            // Tenter le cache en fallback
            if let Ok(cached) = cache.get("prices") {
                warn!("Using cached prices due to API error: {}", e);
                Ok(cached)
            } else {
                Err(ServiceError::ApiUnavailable(e))
            }
        }
    }
}

// ‚úÖ BON - Afficher erreur explicite au lieu de valeurs fausses
match fetch_prices().await {
    Ok(prices) => display_prices(prices),
    Err(e) => display_error("Donn√©es indisponibles", &e),
}
```

---

## üîç PATTERNS DE D√âTECTION AUTOMATIQUE (IA)

### Anti-Patterns √† D√©tecter et Rejeter Imm√©diatement

#### 1. Mock Data / Hard-coded Values
```rust
// PATTERN REGEX: vec!\[.*(?:Price|Trade|Order|User)\s*\{.*(?:value|price|amount):\s*\d+
// ACTION: REJETER + Sugg√©rer fetch depuis API/DB

// ‚ùå D√âTECT√â
vec![Price { symbol: "BTC", value: 50000.0 }]
let users = vec![User { name: "test", id: 1 }];

// ‚úÖ CORRECTION AUTO-SUGG√âR√âE
async fn fetch_prices() -> Result<Vec<Price>, ServiceError> {
    api_client.get_prices().await
}
```

#### 2. Unwrap Sans Contexte
```rust
// PATTERN: \.unwrap\(\)(?!\s*//|\s*/\*)
// ACTION: Remplacer par .expect("message") ou ?

// ‚ùå D√âTECT√â
let value = result.unwrap();
let data = option.unwrap();

// ‚úÖ CORRECTION AUTO
let value = result.expect("Failed to fetch value from API");
// OU
let data = option.ok_or(ServiceError::MissingData)?;
```

#### 3. Import Circulaire
```rust
// D√âTECTION: AST analysis
// Si: service_a imports service_b AND service_b imports service_a
// ACTION: BLOQUER + Sugg√©rer extraction vers models/common.rs

// ‚ùå D√âTECT√â
// services/crypto.rs
use crate::services::portfolio::PortfolioService;

// services/portfolio.rs
use crate::services::crypto::CryptoService;

// ‚úÖ CORRECTION
// Extraire types communs vers models/
// models/portfolio_types.rs
pub struct PortfolioData { /* ... */ }
```

#### 4. Fichier Trop Volumineux
```rust
// D√âTECTION: Compter lignes apr√®s chaque modification
// Si lignes > 280 (warning) ou > 300 (services) ou > 120 (main.rs)
// ACTION: STOP + Demander plan de split

// WORKFLOW IA:
if file_lines > threshold {
    println!("‚ö†Ô∏è FICHIER TROP GROS: {} lignes (max: {})", file_lines, threshold);
    println!("Actions requises:");
    println!("1. Identifier responsabilit√©s distinctes");
    println!("2. Extraire en sous-modules");
    println!("3. Cr√©er mod.rs pour r√©exporter");
    stop_and_request_split_plan();
}
```

#### 5. Clone Excessif
```rust
// PATTERN: Compter .clone() dans une fonction
// Si count > 5: WARN + Sugg√©rer r√©f√©rences ou Cow<>

// ‚ùå D√âTECT√â
fn process(data: Vec<Item>) -> Result<Summary> {
    let copy1 = data.clone();
    let copy2 = data.clone();
    let copy3 = data.clone();
    let copy4 = data.clone();
    let copy5 = data.clone();
    let copy6 = data.clone();  // 6 clones!
}

// ‚úÖ SUGGESTION AUTO
fn process(data: &[Item]) -> Result<Summary> {
    // Utiliser r√©f√©rences
    process_step1(data)?;
    process_step2(data)?;
    // ...
}
```

#### 6. Panic en Production
```rust
// PATTERN: panic!\(|unreachable!\(|unimplemented!\(
// ACTION: REJETER dans src/services/, src/commands/
// ACCEPTER dans src/main.rs (pour setup), tests/

// ‚ùå D√âTECT√â (services/data.rs)
if data.is_empty() {
    panic!("No data!");  // INTERDIT!
}

// ‚úÖ CORRECTION
if data.is_empty() {
    return Err(ServiceError::EmptyData);
}
```

#### 7. Code Comment√© (Dead Code)
```rust
// PATTERN: Lignes cons√©cutives commen√ßant par //
// Si >5 lignes: WARN + Sugg√©rer suppression

// ‚ùå D√âTECT√â
// fn old_implementation() {
//     let x = fetch();
//     process(x);
//     save(x);
// }
// fn another_old_fn() {
//     // ...
// }  // 8+ lignes comment√©es

// ‚úÖ ACTION: Supprimer (historique dans Git)
```

#### 8. Magic Numbers
```rust
// PATTERN: Nombres >1 non-assign√©s √† des constantes
// ACTION: WARN + Sugg√©rer constante nomm√©e

// ‚ùå D√âTECT√â
if price > 10000.0 {  // Magic number!
    timeout = 300;     // Magic number!
}

// ‚úÖ SUGGESTION
const HIGH_PRICE_THRESHOLD: f64 = 10000.0;
const API_TIMEOUT_SECS: u64 = 300;

if price > HIGH_PRICE_THRESHOLD {
    timeout = API_TIMEOUT_SECS;
}
```

#### 9. Unwrap sur Result HTTP/DB
```rust
// PATTERN: reqwest.*\.unwrap|diesel.*\.unwrap
// ACTION: REJETER + Forcer gestion erreur

// ‚ùå D√âTECT√â
let response = client.get(url).send().await.unwrap();  // DANGER!
let user = users.load::<User>(&conn).unwrap();  // DANGER!

// ‚úÖ CORRECTION AUTO
let response = client.get(url)
    .send()
    .await
    .map_err(|e| ServiceError::NetworkError(e.to_string()))?;
```

#### 10. Exposition Excessive (pub)
```rust
// D√âTECTION: Compter pub dans un module
// Si >50% des fonctions sont pub: WARN

// ‚ùå ANTI-PATTERN
pub fn internal_helper() { }  // Pas besoin d'√™tre public!
pub fn another_helper() { }
pub struct InternalCache { }  // Usage interne seulement

// ‚úÖ BON
fn internal_helper() { }  // priv√©
pub fn public_api() { }   // vraiment public
```

### Checklist de D√©tection Automatique (Ex√©cuter Avant Commit)

```rust
// Pseudo-code workflow IA
fn validate_code_before_commit(files: &[FilePath]) -> Result<(), Vec<Violation>> {
    let mut violations = Vec::new();
    
    for file in files {
        // 1. Mock data
        if detect_mock_data(file) {
            violations.push(Violation::MockData { file, line });
        }
        
        // 2. Unwrap sans contexte
        if detect_unsafe_unwrap(file) {
            violations.push(Violation::UnsafeUnwrap { file, line });
        }
        
        // 3. Taille fichier
        if file.lines() > get_max_lines(file.path()) {
            violations.push(Violation::FileTooLarge { file, lines: file.lines() });
        }
        
        // 4. Clone excessif
        if count_clones_in_functions(file) > 5 {
            violations.push(Violation::ExcessiveClone { file, count });
        }
        
        // 5. Magic numbers
        violations.extend(detect_magic_numbers(file));
        
        // 6. Code comment√©
        violations.extend(detect_dead_code(file));
        
        // 7. Panic en production
        if file.is_production_code() && contains_panic(file) {
            violations.push(Violation::PanicInProduction { file, line });
        }
    }
    
    if violations.is_empty() {
        Ok(())
    } else {
        Err(violations)
    }
}
```

---

## üìù TEMPLATES DE G√âN√âRATION DE CODE (IA)

### Template 1: Nouveau Service Complet

```rust
// services/{{SERVICE_NAME}}.rs
use crate::models::errors::ServiceError;
use crate::models::{{domain}}::*;
use crate::db::cache::CacheManager;
use crate::utils::config::Config;
use std::sync::Arc;
use tracing::{info, warn, error, instrument};

/// Service responsable de {{DESCRIPTION}}
///
/// Ce service g√®re:
/// - {{RESPONSABILIT√â_1}}
/// - {{RESPONSABILIT√â_2}}
/// - {{RESPONSABILIT√â_3}}
pub struct {{ServiceName}}Service {
    cache: Arc<CacheManager>,
    config: Arc<Config>,
    // Autres d√©pendances (niveau 1 et 2 uniquement)
}

impl {{ServiceName}}Service {
    /// Cr√©e une nouvelle instance du service
    pub fn new(cache: Arc<CacheManager>, config: Arc<Config>) -> Self {
        info!("Initializing {{ServiceName}}Service");
        Self { cache, config }
    }
    
    /// {{DESCRIPTION DE LA M√âTHODE PRINCIPALE}}
    ///
    /// # Arguments
    ///
    /// * `param1` - {{Description du param√®tre}}
    /// * `param2` - {{Description du param√®tre}}
    ///
    /// # Returns
    ///
    /// `Result<{{ReturnType}}, ServiceError>` - {{Description du retour}}
    ///
    /// # Errors
    ///
    /// Retourne `ServiceError::ApiError` si {{condition}}
    /// Retourne `ServiceError::{{Other}}` si {{condition}}
    ///
    /// # Examples
    ///
    /// ```rust
    /// let result = service.{{method_name}}("param").await?;
    /// ```
    #[instrument(skip(self))]
    pub async fn {{method_name}}(
        &self,
        param1: &str,
        param2: Type,
    ) -> Result<{{ReturnType}}, ServiceError> {
        info!("Calling {{method_name}} with param1={}, param2={:?}", param1, param2);
        
        // 1. Validation des param√®tres
        self.validate_input(param1, param2)?;
        
        // 2. V√©rifier le cache d'abord
        let cache_key = format!("{{domain}}:{}:{}", param1, param2);
        if let Ok(cached) = self.cache.get(&cache_key) {
            info!("Cache hit for {}", cache_key);
            return Ok(cached);
        }
        
        // 3. Logique m√©tier principale
        let result = self.execute_business_logic(param1, param2).await?;
        
        // 4. Mettre en cache le r√©sultat
        self.cache.set("{{domain}}", &cache_key, &result)?;
        
        info!("Successfully completed {{method_name}}");
        Ok(result)
    }
    
    /// Valide les param√®tres d'entr√©e
    fn validate_input(&self, param1: &str, param2: Type) -> Result<(), ServiceError> {
        if param1.is_empty() {
            return Err(ServiceError::InvalidInput("param1 cannot be empty".into()));
        }
        // Autres validations...
        Ok(())
    }
    
    /// Ex√©cute la logique m√©tier principale
    async fn execute_business_logic(
        &self,
        param1: &str,
        param2: Type,
    ) -> Result<{{ReturnType}}, ServiceError> {
        // TODO: Impl√©menter la logique
        todo!("Implement business logic")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use mockall::predicate::*;
    
    fn setup_service() -> {{ServiceName}}Service {
        let cache = Arc::new(CacheManager::new());
        let config = Arc::new(Config::default());
        {{ServiceName}}Service::new(cache, config)
    }
    
    #[tokio::test]
    async fn test_{{method_name}}_success() {
        // Arrange
        let service = setup_service();
        let param1 = "test_value";
        let param2 = Type::default();
        
        // Act
        let result = service.{{method_name}}(param1, param2).await;
        
        // Assert
        assert!(result.is_ok());
        let data = result.unwrap();
        assert_eq!(data.field, expected_value);
    }
    
    #[tokio::test]
    async fn test_{{method_name}}_invalid_input() {
        // Arrange
        let service = setup_service();
        
        // Act
        let result = service.{{method_name}}("", Type::default()).await;
        
        // Assert
        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), ServiceError::InvalidInput(_)));
    }
    
    #[tokio::test]
    async fn test_{{method_name}}_cache_hit() {
        // Arrange
        let service = setup_service();
        let param1 = "cached_value";
        
        // Pr√©-remplir le cache
        service.cache.set("{{domain}}", &format!("{{domain}}:{}", param1), &expected_data).unwrap();
        
        // Act
        let result = service.{{method_name}}(param1, Type::default()).await;
        
        // Assert
        assert!(result.is_ok());
        // V√©rifier que c'est bien les donn√©es du cache
    }
}
```

### Template 2: Nouvelle Tauri Command

```rust
// commands/{{MODULE}}.rs
use tauri::State;
use crate::services::{{service}}::{{Service}}Service;
use crate::models::{{domain}}::*;
use std::sync::Arc;
use serde::{Deserialize, Serialize};
use tracing::{error, info};

/// Request payload pour {{command_name}}
#[derive(Debug, Deserialize)]
pub struct {{Command}}Request {
    pub field1: String,
    pub field2: i64,
    // Autres champs...
}

/// Response payload pour {{command_name}}
#[derive(Debug, Serialize)]
pub struct {{Command}}Response {
    pub data: {{DataType}},
    pub metadata: ResponseMetadata,
}

/// {{DESCRIPTION DE LA COMMAND}}
///
/// Cette command permet de {{OBJECTIF}}
///
/// # Arguments
///
/// * `service` - Instance du service inject√©
/// * `request` - Requ√™te contenant {{DESCRIPTION}}
///
/// # Returns
///
/// `Result<{{Command}}Response, String>` - Donn√©es ou message d'erreur
///
/// # Errors
///
/// Retourne une erreur String si {{CONDITION}}
#[tauri::command]
pub async fn {{command_name}}(
    service: State<'_, Arc<{{Service}}Service>>,
    request: {{Command}}Request,
) -> Result<{{Command}}Response, String> {
    info!("Command {{command_name}} called with: {:?}", request);
    
    // Pas de logique m√©tier ici - seulement bridge vers service
    service
        .{{service_method}}(&request.field1, request.field2)
        .await
        .map(|(data, metadata)| {{Command}}Response { data, metadata })
        .map_err(|e| {
            error!("Command {{command_name}} failed: {}", e);
            format!("Erreur lors de {{command_name}}: {}", e)
        })
}

// Dans main.rs, ajouter √† invoke_handler:
// .invoke_handler(tauri::generate_handler![
//     {{command_name}},
// ])
```

### Template 3: Nouveau Mod√®le de Donn√©es

```rust
// models/{{DOMAIN}}.rs
use serde::{Deserialize, Serialize};
use validator::Validate;

/// {{DESCRIPTION DU MOD√àLE}}
#[derive(Debug, Clone, Serialize, Deserialize, Validate)]
pub struct {{ModelName}} {
    /// {{Description du champ}}
    #[validate(length(min = 1, max = 100))]
    pub id: String,
    
    /// {{Description du champ}}
    #[validate(range(min = 0.0))]
    pub value: f64,
    
    /// {{Description du champ}}
    pub created_at: i64,
    
    // Autres champs...
}

impl {{ModelName}} {
    /// Cr√©e une nouvelle instance avec validation
    pub fn new(id: String, value: f64) -> Result<Self, ValidationError> {
        let instance = Self {
            id,
            value,
            created_at: chrono::Utc::now().timestamp(),
        };
        
        instance.validate()?;
        Ok(instance)
    }
}

/// M√©tadonn√©es de r√©ponse pour tracking et debugging
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResponseMetadata {
    /// Source des donn√©es (API, Cache, Database)
    pub source: DataSource,
    
    /// Timestamp de la requ√™te (Unix timestamp)
    pub timestamp: i64,
    
    /// API utilis√©e (optionnel)
    pub api_used: Option<String>,
    
    /// √Çge du cache en ms (si applicable)
    pub cache_age_ms: Option<i64>,
    
    /// Temps de traitement de la requ√™te en ms
    pub request_time_ms: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum DataSource {
    Api,
    Cache,
    Database,
    Fallback,
}
```

### Template 4: Nouvelle Erreur Personnalis√©e

```rust
// models/errors.rs (ajouter √† l'enum ServiceError)

#[derive(Error, Debug)]
pub enum ServiceError {
    // ... erreurs existantes ...
    
    /// {{DESCRIPTION DE L'ERREUR}}
    #[error("{{MESSAGE D'ERREUR}}: {0}")]
    {{ErrorName}}(String),
    
    /// {{DESCRIPTION}}
    #[error("{{MESSAGE}} - code: {code}, details: {details}")]
    {{ComplexError}} {
        code: i32,
        details: String,
    },
}

// Impl√©mentation de conversion automatique
impl From<{{ExternalError}}> for ServiceError {
    fn from(err: {{ExternalError}}) -> Self {
        ServiceError::{{ErrorName}}(err.to_string())
    }
}
```

### Template 5: Test d'Int√©gration Complet

```rust
// tests/integration_{{feature}}.rs
use {{crate_name}}::services::{{service}}::*;
use {{crate_name}}::models::errors::ServiceError;
use std::sync::Arc;

#[tokio::test]
async fn test_{{feature}}_end_to_end() {
    // 1. Setup
    let config = Arc::new(Config::test_config());
    let cache = Arc::new(CacheManager::new());
    let service = {{Service}}Service::new(cache, config);
    
    // 2. Action
    let result = service.{{method}}("test_param").await;
    
    // 3. Assertions
    assert!(result.is_ok(), "Service should succeed");
    let (data, metadata) = result.unwrap();
    
    assert_eq!(data.len(), 10);
    assert_eq!(metadata.source, DataSource::Api);
    assert!(metadata.request_time_ms < 5000, "Should be fast");
}

#[tokio::test]
async fn test_{{feature}}_error_handling() {
    // Test le comportement en cas d'erreur
    let service = {{Service}}Service::new_with_failing_api();
    
    let result = service.{{method}}("param").await;
    
    assert!(result.is_err());
    assert!(matches!(result.unwrap_err(), ServiceError::ApiError(_)));
}

#[tokio::test]
async fn test_{{feature}}_cache_fallback() {
    // Test le fallback sur cache quand API √©choue
    let service = {{Service}}Service::new_with_failing_api();
    
    // Pr√©-remplir le cache
    service.cache.set("domain", "key", &mock_data()).unwrap();
    
    let result = service.{{method}}("param").await;
    
    assert!(result.is_ok());
    let (_, metadata) = result.unwrap();
    assert_eq!(metadata.source, DataSource::Cache);
}
```

### Template 6: Configuration Module

```rust
// utils/config.rs
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use crate::models::errors::ServiceError;

/// Configuration principale de l'application
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    /// Configuration des API externes
    pub api: ApiConfig,
    
    /// Configuration du cache
    pub cache: CacheConfig,
    
    /// Configuration de la base de donn√©es
    pub database: DatabaseConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ApiConfig {
    pub base_url: String,
    pub timeout_secs: u64,
    pub rate_limit_per_min: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheConfig {
    pub enabled: bool,
    pub ttl_secs: HashMap<String, u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DatabaseConfig {
    pub path: PathBuf,
    pub pool_size: u32,
}

impl Config {
    /// Charge la configuration depuis un fichier
    pub fn load_from_file(path: &PathBuf) -> Result<Self, ServiceError> {
        let content = std::fs::read_to_string(path)
            .map_err(|e| ServiceError::ConfigError(e.to_string()))?;
        
        toml::from_str(&content)
            .map_err(|e| ServiceError::ConfigError(e.to_string()))
    }
    
    /// Configuration par d√©faut pour tests
    #[cfg(test)]
    pub fn test_config() -> Self {
        Self {
            api: ApiConfig {
                base_url: "http://localhost:8080".into(),
                timeout_secs: 30,
                rate_limit_per_min: 60,
            },
            cache: CacheConfig {
                enabled: true,
                ttl_secs: HashMap::from([
                    ("crypto".into(), 300),
                    ("test".into(), 60),
                ]),
            },
            database: DatabaseConfig {
                path: PathBuf::from(":memory:"),
                pool_size: 5,
            },
        }
    }
}
```

### Usage des Templates (IA)

```rust
// Workflow pour g√©n√©rer nouveau service:
fn generate_new_service(name: &str, domain: &str) -> String {
    TEMPLATE_SERVICE
        .replace("{{SERVICE_NAME}}", &name.to_snake_case())
        .replace("{{ServiceName}}", &name.to_pascal_case())
        .replace("{{DESCRIPTION}}", &format!("gestion des {}", domain))
        .replace("{{domain}}", domain)
        .replace("{{ReturnType}}", "Vec<DataType>")
        .replace("{{method_name}}", "fetch_data")
}

// L'IA doit:
// 1. Identifier les placeholders {{}}
// 2. Demander valeurs √† l'utilisateur SI n√©cessaire
// 3. Remplacer tous les placeholders
// 4. G√©n√©rer le fichier
// 5. Ex√©cuter cargo fmt
// 6. V√©rifier compilation
```

---

### Structure de Projet Obligatoire

```
project_root/
‚îú‚îÄ‚îÄ src-tauri/                    # Backend Rust
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.rs              # Entry point (<100 lignes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib.rs               # Module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands/            # Tauri commands (API frontend)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crypto.rs        # Commandes crypto
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.rs      # Commandes settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_client.rs    # API externe
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.rs         # Cache centralis√©
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_service.rs  # Service m√©tier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              # Data structures
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crypto.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ errors.rs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/                  # Persistance (SQLite/Diesel)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/               # Helpers
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config.rs
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ logger.rs
‚îÇ   ‚îú‚îÄ‚îÄ Cargo.toml
‚îÇ   ‚îî‚îÄ‚îÄ build.rs
‚îú‚îÄ‚îÄ src/                         # Frontend (HTML/JS minimal ou aucun)
‚îú‚îÄ‚îÄ tests/                       # Tests d'int√©gration
‚îú‚îÄ‚îÄ .clinerules                  # Ce fichier
‚îî‚îÄ‚îÄ README.md
```

### Limites de Taille de Fichier (STRICT)

```
| Type Fichier       | Max Lignes | Hard Limit | Pourquoi |
|--------------------|------------|------------|----------|
| main.rs            | 100        | 120        | Entry point minimal |
| Tauri commands     | 150        | 180        | API endpoints clairs |
| Services           | 300        | 350        | Business logic complexe |
| Models/Structs     | 200        | 250        | Data definitions |
| Tests unitaires    | 500        | -          | Pas de limite (testabilit√© prioritaire) |
| Modules utils      | 200        | 250        | Helpers focused |
```

**Si fichier d√©passe Hard Limit:**
```
‚ùå FAIL: Build √©choue, audit signale violation
‚úÖ FIX: DOIT split en sous-modules

Strat√©gie:
1. Identifier les responsabilit√©s distinctes
2. Extraire en modules s√©par√©s
3. Importer et composer
4. V√©rifier CHAQUE fichier < Max Lignes
```

### Service Dependency Hierarchy (DAG - Directed Acyclic Graph)

**Architecture en 3 niveaux:**

```
NIVEAU 1: BASE SERVICES (z√©ro d√©pendance externe)
  ‚úì utils/config.rs           (configuration centralis√©e)
  ‚úì utils/logger.rs           (logging structur√©)
  ‚úì models/errors.rs          (types d'erreurs)
  
  ‚îú‚îÄ‚îÄ D√©pendances: AUCUNE autre que std/serde
  ‚îî‚îÄ‚îÄ Import only: config constants

NIVEAU 2: DATA SERVICES (d√©pendent SEULEMENT Niveau 1)
  ‚úì db/cache.rs               (cache centralis√©)
  ‚úì services/api_client.rs    (client HTTP)
  ‚úì db/repository.rs          (acc√®s base de donn√©es)
  
  ‚îú‚îÄ‚îÄ Peuvent importer: Niveau 1 SEULEMENT
  ‚îî‚îÄ‚îÄ JAMAIS importer d'autres services Niveau 2

NIVEAU 3: BUSINESS LOGIC (d√©pendent Niveau 1 + 2)
  ‚úì services/data_service.rs  (orchestration m√©tier)
  ‚úì services/trading.rs       (logique trading)
  
  ‚îú‚îÄ‚îÄ Peuvent importer: Niveau 1 + Niveau 2
  ‚îî‚îÄ‚îÄ JAMAIS importer commands ou main

NIVEAU 4: API LAYER
  ‚úì commands/*.rs             (Tauri commands)
  
  ‚îú‚îÄ‚îÄ Importe UNIQUEMENT: Business Logic (Niveau 3)
  ‚îî‚îÄ‚îÄ Jamais d'appels directs aux services Niveau 2
```

### Interdictions Strictes

```
‚ùå JAMAIS permettre:
  - Import circulaire (A ‚Üí B ‚Üí A)
  - Service importe autre service de son niveau
  - Command appelle directement db/cache (passer par service)
  - Unwrap() sans contexte (utiliser expect() ou ?)
  - Clone() excessif (utiliser r√©f√©rences)
  - Fichiers nomm√©s _broken, _old, _test, _backup
  - Code comment√© >5 lignes
  - Fonction jamais utilis√©e (dead code)
  - pub sur tout (exposer seulement le n√©cessaire)
```

---

## üìä GESTION DES DONN√âES (RUST SP√âCIFIQUE)

### Unified Result Type (OBLIGATOIRE)

**TOUS les services retournent Result<T, ServiceError>:**

```rust
// models/errors.rs
use thiserror::Error;

#[derive(Error, Debug)]
pub enum ServiceError {
    #[error("API error: {0}")]
    ApiError(String),
    
    #[error("Network timeout after {0}s")]
    Timeout(u64),
    
    #[error("Rate limit exceeded")]
    RateLimit,
    
    #[error("Database error: {0}")]
    Database(#[from] diesel::result::Error),
    
    #[error("Cache error: {0}")]
    Cache(String),
    
    #[error("Parse error: {0}")]
    Parse(String),
    
    #[error("Invalid API key")]
    InvalidKey,
}

// M√©tadonn√©es pour debugging
#[derive(Debug, Clone, Serialize)]
pub struct ResponseMetadata {
    pub source: DataSource,      // API, Cache, Database
    pub timestamp: i64,           // Unix timestamp
    pub api_used: Option<String>, // "coingecko", "binance"
    pub cache_age_ms: Option<i64>,
    pub request_time_ms: u64,
}

#[derive(Debug, Clone, Serialize)]
pub enum DataSource {
    Api,
    Cache,
    Database,
    Fallback,
}
```

**Utilisation dans services:**

```rust
// services/data_service.rs
pub async fn fetch_crypto_prices(
    &self,
    vs_currency: &str,
) -> Result<(Vec<CryptoPrice>, ResponseMetadata), ServiceError> {
    let start = Instant::now();
    
    // Tenter API d'abord
    match self.api_client.get_prices(vs_currency).await {
        Ok(prices) => {
            // Mettre en cache
            self.cache.set("prices", &prices)?;
            
            Ok((prices, ResponseMetadata {
                source: DataSource::Api,
                timestamp: Utc::now().timestamp(),
                api_used: Some("coingecko".to_string()),
                cache_age_ms: None,
                request_time_ms: start.elapsed().as_millis() as u64,
            }))
        }
        Err(e) => {
            warn!("API failed, trying cache: {}", e);
            
            // Fallback sur cache
            if let Ok(cached) = self.cache.get::<Vec<CryptoPrice>>("prices") {
                Ok((cached.data, ResponseMetadata {
                    source: DataSource::Cache,
                    timestamp: Utc::now().timestamp(),
                    api_used: None,
                    cache_age_ms: Some(cached.age_ms),
                    request_time_ms: start.elapsed().as_millis() as u64,
                }))
            } else {
                Err(ServiceError::ApiError(e.to_string()))
            }
        }
    }
}
```

### Cache Centralization (OBLIGATOIRE)

**Tous les services DOIVENT utiliser un cache centralis√©:**

```rust
// db/cache.rs
use std::time::{Duration, Instant};
use serde::{Serialize, Deserialize};

pub struct CacheManager {
    store: Arc<RwLock<HashMap<String, CacheEntry>>>,
    ttls: HashMap<&'static str, Duration>,
}

struct CacheEntry {
    data: Vec<u8>,
    created_at: Instant,
    cache_type: &'static str,
}

impl CacheManager {
    pub fn new() -> Self {
        let mut ttls = HashMap::new();
        ttls.insert("crypto", Duration::from_secs(300));      // 5 min
        ttls.insert("forex", Duration::from_secs(60));        // 1 min
        ttls.insert("stocks", Duration::from_secs(300));      // 5 min
        ttls.insert("news", Duration::from_secs(3600));       // 1 heure
        ttls.insert("announcements", Duration::from_secs(86400)); // 24h
        
        Self {
            store: Arc::new(RwLock::new(HashMap::new())),
            ttls,
        }
    }
    
    pub fn get<T: DeserializeOwned>(
        &self,
        key: &str,
    ) -> Result<CachedData<T>, ServiceError> {
        let store = self.store.read().unwrap();
        
        if let Some(entry) = store.get(key) {
            let age = entry.created_at.elapsed();
            let ttl = self.ttls.get(entry.cache_type)
                .ok_or_else(|| ServiceError::Cache("Unknown cache type".into()))?;
            
            if age < *ttl {
                let data: T = bincode::deserialize(&entry.data)
                    .map_err(|e| ServiceError::Parse(e.to_string()))?;
                
                return Ok(CachedData {
                    data,
                    age_ms: age.as_millis() as i64,
                });
            }
        }
        
        Err(ServiceError::Cache("Not found or expired".into()))
    }
    
    pub fn set<T: Serialize>(
        &self,
        cache_type: &'static str,
        key: &str,
        data: &T,
    ) -> Result<(), ServiceError> {
        let serialized = bincode::serialize(data)
            .map_err(|e| ServiceError::Parse(e.to_string()))?;
        
        let mut store = self.store.write().unwrap();
        store.insert(key.to_string(), CacheEntry {
            data: serialized,
            created_at: Instant::now(),
            cache_type,
        });
        
        Ok(())
    }
}

pub struct CachedData<T> {
    pub data: T,
    pub age_ms: i64,
}
```

---

## üîí S√âCURIT√â (RUST-SPECIFIC)

### Gestion des Secrets

```rust
// ‚úÖ BON: Variables d'environnement + chiffrement
use tauri::api::path::app_config_dir;
use aes_gcm::{Aes256Gcm, Key, Nonce};

pub struct SecureConfig {
    cipher: Aes256Gcm,
    config_path: PathBuf,
}

impl SecureConfig {
    pub fn load_api_key(&self, service: &str) -> Result<String, ServiceError> {
        // Lire depuis fichier chiffr√©
        let encrypted = fs::read(self.config_path.join(format!("{}.enc", service)))?;
        
        // D√©chiffrer
        let decrypted = self.cipher.decrypt(&encrypted)?;
        
        Ok(String::from_utf8(decrypted)?)
    }
    
    pub fn save_api_key(&self, service: &str, key: &str) -> Result<(), ServiceError> {
        // Chiffrer
        let encrypted = self.cipher.encrypt(key.as_bytes())?;
        
        // Sauvegarder
        fs::write(self.config_path.join(format!("{}.enc", service)), encrypted)?;
        
        Ok(())
    }
}

// ‚ùå MAUVAIS: Cl√©s en dur
const API_KEY: &str = "sk-1234567890abcdef";  // JAMAIS!
```

### Validation des Entr√©es (OBLIGATOIRE)

```rust
// Utiliser validator crate
use validator::{Validate, ValidationError};

#[derive(Debug, Validate, Deserialize)]
pub struct CreateOrderRequest {
    #[validate(length(min = 1, max = 10))]
    pub symbol: String,
    
    #[validate(range(min = 0.0, max = 1000000.0))]
    pub quantity: f64,
    
    #[validate(custom = "validate_order_type")]
    pub order_type: String,
}

fn validate_order_type(order_type: &str) -> Result<(), ValidationError> {
    match order_type {
        "market" | "limit" | "stop" => Ok(()),
        _ => Err(ValidationError::new("invalid_order_type")),
    }
}

// Dans command
#[tauri::command]
pub async fn create_order(
    request: CreateOrderRequest,
) -> Result<Order, String> {
    // Valider automatiquement
    request.validate()
        .map_err(|e| format!("Validation error: {}", e))?;
    
    // Traiter...
}
```

---

## ÔøΩ PATTERNS DE REFACTORING AUTOMATIQUE (IA)

### Pattern 1: Extraire Fonction Trop Longue

```rust
// D√âTECTION: Fonction >50 lignes
// ACTION: Proposer split en sous-fonctions

// ‚ùå AVANT: Fonction monolithique 80 lignes
pub async fn process_crypto_data(symbols: Vec<String>) -> Result<Summary, ServiceError> {
    // Validation (15 lignes)
    if symbols.is_empty() {
        return Err(ServiceError::InvalidInput("symbols cannot be empty".into()));
    }
    for symbol in &symbols {
        if symbol.len() < 2 || symbol.len() > 10 {
            return Err(ServiceError::InvalidInput(format!("Invalid symbol: {}", symbol)));
        }
    }
    
    // Fetching (20 lignes)
    let mut prices = Vec::new();
    for symbol in &symbols {
        match api_client.get_price(symbol).await {
            Ok(price) => prices.push(price),
            Err(e) => warn!("Failed to fetch {}: {}", symbol, e),
        }
    }
    
    // Transformation (20 lignes)
    let mut transformed = Vec::new();
    for price in prices {
        let normalized = price.value / 100.0;
        let with_fee = normalized * 1.01;
        transformed.push(TransformedPrice {
            symbol: price.symbol,
            value: with_fee,
        });
    }
    
    // Aggregation (15 lignes)
    let total: f64 = transformed.iter().map(|p| p.value).sum();
    let average = total / transformed.len() as f64;
    Ok(Summary { total, average, count: transformed.len() })
}

// ‚úÖ APR√àS: Split en 4 fonctions claires
pub async fn process_crypto_data(symbols: Vec<String>) -> Result<Summary, ServiceError> {
    validate_symbols(&symbols)?;
    let prices = fetch_prices(&symbols).await?;
    let transformed = transform_prices(&prices);
    aggregate_results(&transformed)
}

fn validate_symbols(symbols: &[String]) -> Result<(), ServiceError> {
    if symbols.is_empty() {
        return Err(ServiceError::InvalidInput("symbols cannot be empty".into()));
    }
    for symbol in symbols {
        if symbol.len() < 2 || symbol.len() > 10 {
            return Err(ServiceError::InvalidInput(format!("Invalid symbol: {}", symbol)));
        }
    }
    Ok(())
}

async fn fetch_prices(symbols: &[String]) -> Result<Vec<Price>, ServiceError> {
    let mut prices = Vec::new();
    for symbol in symbols {
        match api_client.get_price(symbol).await {
            Ok(price) => prices.push(price),
            Err(e) => warn!("Failed to fetch {}: {}", symbol, e),
        }
    }
    if prices.is_empty() {
        Err(ServiceError::NoDataFetched)
    } else {
        Ok(prices)
    }
}

fn transform_prices(prices: &[Price]) -> Vec<TransformedPrice> {
    prices.iter()
        .map(|price| {
            let normalized = price.value / 100.0;
            let with_fee = normalized * 1.01;
            TransformedPrice {
                symbol: price.symbol.clone(),
                value: with_fee,
            }
        })
        .collect()
}

fn aggregate_results(transformed: &[TransformedPrice]) -> Result<Summary, ServiceError> {
    if transformed.is_empty() {
        return Err(ServiceError::EmptyData);
    }
    let total: f64 = transformed.iter().map(|p| p.value).sum();
    let average = total / transformed.len() as f64;
    Ok(Summary { total, average, count: transformed.len() })
}
```

### Pattern 2: Remplacer unwrap() par Gestion d'Erreur

```rust
// D√âTECTION: \.unwrap\(\)
// ACTION: Remplacer par ? ou expect() avec message

// ‚ùå AVANT
let config = load_config().unwrap();
let value = parse_data(input).unwrap();
let user = db.find_user(id).unwrap();

// ‚úÖ APR√àS (Option 1: Propagation avec ?)
let config = load_config()?;
let value = parse_data(input)?;
let user = db.find_user(id)?;

// ‚úÖ APR√àS (Option 2: expect() avec message)
let config = load_config()
    .expect("Failed to load config - check config.toml exists");
let value = parse_data(input)
    .expect("Failed to parse input - invalid format");

// ‚úÖ APR√àS (Option 3: Conversion d'erreur explicite)
let config = load_config()
    .map_err(|e| ServiceError::ConfigError(e.to_string()))?;
let user = db.find_user(id)
    .ok_or(ServiceError::UserNotFound(id))?;
```

### Pattern 3: Centraliser Magic Numbers

```rust
// D√âTECTION: Nombres litt√©raux >1 utilis√©s plusieurs fois
// ACTION: Extraire en constantes nomm√©es

// ‚ùå AVANT
if price > 10000.0 {
    apply_high_price_strategy();
}
if volume > 1000000.0 {
    alert_high_volume();
}
setTimeout(300);  // 300 quoi?
cache.set_ttl(3600);  // 3600 quoi?

// ‚úÖ APR√àS
// En haut du fichier ou dans config
const HIGH_PRICE_THRESHOLD: f64 = 10000.0;
const HIGH_VOLUME_THRESHOLD: f64 = 1_000_000.0;
const API_TIMEOUT_SECS: u64 = 300;
const CACHE_TTL_SECS: u64 = 3600;

if price > HIGH_PRICE_THRESHOLD {
    apply_high_price_strategy();
}
if volume > HIGH_VOLUME_THRESHOLD {
    alert_high_volume();
}
setTimeout(API_TIMEOUT_SECS);
cache.set_ttl(CACHE_TTL_SECS);
```

### Pattern 4: Simplifier Clones Excessifs

```rust
// D√âTECTION: >3 .clone() dans une fonction
// ACTION: Utiliser r√©f√©rences ou Cow<>

// ‚ùå AVANT
fn process_data(data: Vec<Item>) -> Result<Summary> {
    let copy1 = data.clone();  // Clone 1
    let copy2 = data.clone();  // Clone 2
    let copy3 = data.clone();  // Clone 3
    let copy4 = data.clone();  // Clone 4
    
    validate(&copy1)?;
    transform(&copy2)?;
    aggregate(&copy3)?;
    save(&copy4)?;
    Ok(Summary::new())
}

// ‚úÖ APR√àS: Utiliser r√©f√©rences
fn process_data(data: &[Item]) -> Result<Summary> {
    validate(data)?;
    let transformed = transform(data)?;  // Retourne nouveau Vec si besoin
    let aggregated = aggregate(&transformed)?;
    save(&aggregated)?;
    Ok(Summary::new())
}

// ‚úÖ APR√àS: Ou utiliser Cow pour clone conditionnel
use std::borrow::Cow;

fn format_symbol<'a>(symbol: &'a str) -> Cow<'a, str> {
    if symbol.starts_with("BTC") {
        Cow::Borrowed(symbol)  // Pas de clone
    } else {
        Cow::Owned(format!("{}USD", symbol))  // Clone seulement si modifi√©
    }
}
```

### Pattern 5: Regrouper Code Dupliqu√©

```rust
// D√âTECTION: Blocs de code similaires r√©p√©t√©s
// ACTION: Extraire en fonction g√©n√©rique ou trait

// ‚ùå AVANT: Duplication
fn fetch_btc_price() -> Result<Price, ServiceError> {
    let url = format!("{}/btc", BASE_URL);
    let response = client.get(&url).send().await?;
    if !response.status().is_success() {
        return Err(ServiceError::ApiError("BTC fetch failed".into()));
    }
    let price: Price = response.json().await?;
    Ok(price)
}

fn fetch_eth_price() -> Result<Price, ServiceError> {
    let url = format!("{}/eth", BASE_URL);
    let response = client.get(&url).send().await?;
    if !response.status().is_success() {
        return Err(ServiceError::ApiError("ETH fetch failed".into()));
    }
    let price: Price = response.json().await?;
    Ok(price)
}

// ‚úÖ APR√àS: Factoriser
async fn fetch_price(symbol: &str) -> Result<Price, ServiceError> {
    let url = format!("{}/{}", BASE_URL, symbol.to_lowercase());
    let response = client.get(&url).send().await?;
    
    if !response.status().is_success() {
        return Err(ServiceError::ApiError(
            format!("{} fetch failed: {}", symbol, response.status())
        ));
    }
    
    response.json().await
        .map_err(|e| ServiceError::ParseError(e.to_string()))
}

// Utilisation
let btc = fetch_price("BTC").await?;
let eth = fetch_price("ETH").await?;
```

### Pattern 6: Simplifier Nested Match/If

```rust
// D√âTECTION: >3 niveaux d'imbrication
// ACTION: Early returns ou combinateurs

// ‚ùå AVANT: Imbrication profonde
fn process(data: Option<Data>) -> Result<Output, ServiceError> {
    if let Some(data) = data {
        if data.is_valid() {
            if let Some(value) = data.value {
                if value > 0.0 {
                    Ok(Output::new(value))
                } else {
                    Err(ServiceError::InvalidValue)
                }
            } else {
                Err(ServiceError::MissingValue)
            }
        } else {
            Err(ServiceError::InvalidData)
        }
    } else {
        Err(ServiceError::NoData)
    }
}

// ‚úÖ APR√àS: Early returns
fn process(data: Option<Data>) -> Result<Output, ServiceError> {
    let data = data.ok_or(ServiceError::NoData)?;
    
    if !data.is_valid() {
        return Err(ServiceError::InvalidData);
    }
    
    let value = data.value.ok_or(ServiceError::MissingValue)?;
    
    if value <= 0.0 {
        return Err(ServiceError::InvalidValue);
    }
    
    Ok(Output::new(value))
}

// ‚úÖ OU: Combinateurs
fn process(data: Option<Data>) -> Result<Output, ServiceError> {
    data.ok_or(ServiceError::NoData)?
        .validate()?
        .value
        .ok_or(ServiceError::MissingValue)?
        .validate_positive()
        .map(Output::new)
}
```

### Pattern 7: Supprimer Code Comment√©

```rust
// D√âTECTION: >5 lignes cons√©cutives comment√©es
// ACTION: Supprimer (historique dans Git)

// ‚ùå AVANT
pub fn calculate() -> f64 {
    let result = new_calculation();
    // fn old_calculation() -> f64 {
    //     let x = fetch_data();
    //     let y = process(x);
    //     let z = transform(y);
    //     z * 1.5
    // }
    // 
    // fn another_old_approach() {
    //     // ... encore plus de code mort
    // }
    result
}

// ‚úÖ APR√àS: Supprimer tout le code comment√©
pub fn calculate() -> f64 {
    new_calculation()
}
// Si vraiment n√©cessaire, consulter l'historique Git
```

### Automatisation du Refactoring

```rust
// Workflow IA pour refactoring automatique
fn auto_refactor_suggestions(file: &File) -> Vec<RefactoringSuggestion> {
    let mut suggestions = Vec::new();
    
    // 1. Fonctions trop longues
    for function in file.functions() {
        if function.lines() > 50 {
            suggestions.push(RefactoringSuggestion::SplitFunction {
                name: function.name(),
                current_lines: function.lines(),
                suggested_split: identify_logical_blocks(function),
            });
        }
    }
    
    // 2. unwrap() non s√©curis√©s
    for unwrap in file.find_unwraps() {
        suggestions.push(RefactoringSuggestion::ReplaceUnwrap {
            line: unwrap.line,
            replacement: generate_safe_unwrap(unwrap),
        });
    }
    
    // 3. Magic numbers
    for number in file.find_magic_numbers() {
        if number.occurrences > 1 {
            suggestions.push(RefactoringSuggestion::ExtractConstant {
                value: number.value,
                suggested_name: generate_constant_name(&number),
                occurrences: number.occurrences,
            });
        }
    }
    
    // 4. Clones excessifs
    for function in file.functions() {
        let clone_count = function.count_clones();
        if clone_count > 5 {
            suggestions.push(RefactoringSuggestion::ReduceClones {
                function: function.name(),
                clone_count,
                suggestion: "Use references instead",
            });
        }
    }
    
    suggestions
}
```

---

## ÔøΩüìù DOCUMENTATION ET COMMENTAIRES

### Documentation Rust (Obligatoire)

```rust
/// R√©cup√®re les prix des cryptomonnaies depuis l'API
///
/// # Arguments
///
/// * `vs_currency` - Devise de r√©f√©rence (usd, eur, etc.)
/// * `limit` - Nombre maximum d'assets √† r√©cup√©rer
/// * `use_cache` - Si true, utilise le cache si disponible
///
/// # Returns
///
/// `Result<Vec<CryptoPrice>, ServiceError>` - Liste des prix ou erreur
///
/// # Errors
///
/// Retourne `ServiceError::ApiError` si l'API est indisponible
/// Retourne `ServiceError::RateLimit` si rate limit atteint
///
/// # Examples
///
/// ```
/// let prices = service.fetch_prices("usd", 100, true).await?;
/// ```
pub async fn fetch_prices(
    &self,
    vs_currency: &str,
    limit: usize,
    use_cache: bool,
) -> Result<Vec<CryptoPrice>, ServiceError> {
    // Implementation
}
```

### Commentaires de Code

```rust
// ‚úÖ BON: Explique le "pourquoi"
// Utiliser bincode au lieu de JSON pour 3x moins de bytes
let serialized = bincode::serialize(&data)?;

// ‚úÖ BON: Justifie une d√©cision technique
// Clone n√©cessaire car data sera utilis√© dans plusieurs threads
let data_clone = data.clone();

// ‚ùå MAUVAIS: Explique le "quoi" (√©vident)
// Incr√©mente le compteur
counter += 1;
```

---

## üí¨ NIVEAUX DE VERBOSIT√â ADAPTATIVE (IA)

### Quand √ätre VERBEUX (D√©tails Complets)

```rust
// Contextes n√©cessitant communication d√©taill√©e:

// 1. CHANGEMENTS ARCHITECTURAUX MAJEURS
println!("üèóÔ∏è CHANGEMENT ARCHITECTURAL MAJEUR\n");
println!("Action: Split de data_service.rs (380 lignes) en 3 modules");
println!("\nPourquoi:");
println!("  - Fichier d√©passait hard limit (300 lignes)");
println!("  - 3 responsabilit√©s distinctes identifi√©es");
println!("\nImpact:");
println!("  - data_service.rs ‚Üí 120 lignes (API facade)");
println!("  - crypto_data.rs ‚Üí 140 lignes (crypto logic)");
println!("  - forex_data.rs ‚Üí 120 lignes (forex logic)");
println!("\nFichiers affect√©s:");
println!("  - src/services/data_service.rs (modifi√©)");
println!("  - src/services/crypto_data.rs (nouveau)");
println!("  - src/services/forex_data.rs (nouveau)");
println!("  - src/services/mod.rs (exports mis √† jour)");
println!("\nAlternative consid√©r√©e:");
println!("  - Garder un seul fichier avec #[allow(long_file)]");
println!("  - Rejet√©e: Viole principe de responsabilit√© unique");
println!("\nTests:");
println!("  ‚úÖ Tous les tests passent");
println!("  ‚úÖ Coverage maintenu √† 85%");

// 2. BREAKING CHANGES API
println!("‚ö†Ô∏è BREAKING CHANGE D√âTECT√â\n");
println!("Fonction modifi√©e: fetch_prices()");
println!("Ancienne signature:");
println!("  pub async fn fetch_prices(currency: &str) -> Vec<Price>");
println!("\nNouvelle signature:");
println!("  pub async fn fetch_prices(currency: &str) -> Result<Vec<Price>, ServiceError>");
println!("\nRaison:");
println!("  - Gestion d'erreur explicite obligatoire (Principe #3)");
println!("  - Pas de panic! en cas d'√©chec API");
println!("\nImpact:");
println!("  - 5 fichiers √† mettre √† jour:");
println!("    ‚Ä¢ commands/crypto.rs");
println!("    ‚Ä¢ services/portfolio.rs");
println!("    ‚Ä¢ tests/integration_test.rs");
println!("    ‚Ä¢ examples/fetch_demo.rs");
println!("    ‚Ä¢ scripts/import_data.rs");
println!("\nAction:");
println!("  - Mise √† jour automatique effectu√©e");
println!("  - V√©rification manuelle recommand√©e");

// 3. D√âCISIONS TECHNIQUES CONTROVERS√âES
println!("ü§î D√âCISION TECHNIQUE N√âCESSAIRE\n");
println!("Probl√®me: Performance O(n¬≤) d√©tect√©e dans calculate_correlations()");
println!("\nOptions:");
println!("  A) Optimiser vers O(n log n) avec HashMap");
println!("     + Gain: ~800ms pour 10k items");
println!("     - Complexit√© code: +45 lignes");
println!("     - Lisibilit√© r√©duite");
println!("\n  B) Garder code actuel");
println!("     + Clart√© maximale");
println!("     - Performance acceptable seulement <1k items");
println!("\nRecommandation: Option A");
println!("Justification: L'app traitera >5k items r√©guli√®rement");

// 4. ERREURS BLOQUANTES
eprintln!("üî¥ ERREUR BLOQUANTE - COMMIT IMPOSSIBLE\n");
eprintln!("Type: Tests √©chou√©s (3/47)");
eprintln!("\nTests en √©chec:");
eprintln!("  1. test_fetch_prices_success");
eprintln!("     Erreur: assertion failed: prices.len() == 10");
eprintln!("     Valeur attendue: 10, r√©elle: 0");
eprintln!("     Fichier: tests/service_test.rs:42");
eprintln!("\n  2. test_cache_fallback");
eprintln!("     Erreur: ServiceError::CacheNotFound");
eprintln!("     Fichier: tests/service_test.rs:58");
eprintln!("\nAction requise:");
eprintln!("  1. D√©bugger test_fetch_prices_success");
eprintln!("  2. V√©rifier mock API retourne bien donn√©es");
eprintln!("  3. Re-ex√©cuter tests");
eprintln!("\n‚ùå COMMIT BLOQU√â jusqu'√† r√©solution");
```

### Quand √ätre CONCIS (Messages Courts)

```rust
// Contextes permettant messages courts:

// 1. FIXES SIMPLES
println!("‚úÖ Fixed typo in data_service.rs");

// 2. AJOUT DE TESTS
println!("‚úÖ Added 3 tests for crypto_service");
println!("   Coverage: 82% ‚Üí 87%");

// 3. DOCUMENTATION
println!("üìù Added doc comments to 5 public functions");

// 4. REFACTORING SANS IMPACT API
println!("‚ôªÔ∏è  Refactored internal cache logic");
println!("   No API changes");

// 5. FORMATAGE
println!("üé® Applied cargo fmt to 12 files");

// 6. D√âPENDANCES
println!("üì¶ Updated serde 1.0.195 ‚Üí 1.0.196");
```

### Format de Communication Structur√©

```rust
enum MessageVerbosity {
    Minimal,   // 1 ligne
    Standard,  // 2-5 lignes
    Detailed,  // 5-15 lignes
    Verbose,   // >15 lignes avec structure compl√®te
}

struct AiMessage {
    icon: &'static str,
    title: String,
    verbosity: MessageVerbosity,
    sections: Vec<MessageSection>,
}

struct MessageSection {
    title: String,
    content: Vec<String>,
    sub_items: Vec<String>,
}

// Exemple d'utilisation
let message = AiMessage {
    icon: "üèóÔ∏è",
    title: "ARCHITECTURE CHANGE".into(),
    verbosity: MessageVerbosity::Verbose,
    sections: vec![
        MessageSection {
            title: "Pourquoi".into(),
            content: vec!["File too large (380 lines)".into()],
            sub_items: vec![],
        },
        MessageSection {
            title: "Impact".into(),
            content: vec!["3 files created, 1 modified".into()],
            sub_items: vec![
                "data_service.rs ‚Üí 120L".into(),
                "crypto_data.rs ‚Üí 140L (new)".into(),
            ],
        },
    ],
};

// Rendu:
// üèóÔ∏è ARCHITECTURE CHANGE
// 
// Pourquoi:
//   File too large (380 lines)
// 
// Impact:
//   3 files created, 1 modified
//   - data_service.rs ‚Üí 120L
//   - crypto_data.rs ‚Üí 140L (new)
```

### Logs Structur√©s pour Tra√ßabilit√©

```json
// Format JSON pour logs machine-readable
{
  "timestamp": "2025-10-31T14:32:18Z",
  "action": "refactor_service",
  "severity": "info",
  "details": {
    "file": "src/services/data_service.rs",
    "reason": "file_too_large",
    "before": {
      "lines": 380,
      "functions": 25,
      "tests": 15
    },
    "after": {
      "files": [
        {"path": "src/services/data_service.rs", "lines": 120},
        {"path": "src/services/crypto_data.rs", "lines": 140},
        {"path": "src/services/forex_data.rs", "lines": 120}
      ],
      "functions": 25,
      "tests": 15
    },
    "tests_passing": true,
    "coverage_delta": 0,
    "build_success": true
  }
}
```

---

## üìã GESTION DE LA DETTE TECHNIQUE (IA)

### Format TODO Standard

```rust
// TODO(IA-YYYY-MM-DD): Description claire de ce qui doit √™tre fait
// Raison diff√©r√©: Explication du pourquoi pas maintenant
// Impact actuel: Quel est l'impact de ne pas le faire tout de suite
// Priorit√©: Low | Medium | High | Critical
// Issue: #123 (lien GitHub si applicable)

// Exemple 1: Optimisation diff√©r√©e
// TODO(IA-2025-10-31): Optimiser cette boucle (O(n¬≤) ‚Üí O(n log n))
// Raison diff√©r√©: N√©cessite restructuration majeure du cache
// Impact actuel: Acceptable pour <1000 items (usage typique: 200)
// Priorit√©: Low
// Issue: #234

// Exemple 2: Refactoring n√©cessaire
// TODO(IA-2025-10-31): Split cette fonction (120 lignes ‚Üí 3 fonctions)
// Raison diff√©r√©: Attente validation architecture par user
// Impact actuel: Code fonctionne mais moins maintenable
// Priorit√©: Medium
// Issue: #235

// Exemple 3: Feature manquante
// TODO(IA-2025-10-31): Ajouter retry logic pour API calls
// Raison diff√©r√©: N√©cessite choix strat√©gie retry (exponential backoff?)
// Impact actuel: Erreurs transitoires causent √©checs
// Priorit√©: High
// Issue: #236
```

### Tracking Automatique de la Dette

```rust
// L'IA maintient un fichier TECH_DEBT.md

struct TechDebt {
    id: u32,
    description: String,
    file: PathBuf,
    line: u32,
    created_date: String,
    priority: Priority,
    impact: Impact,
    estimated_hours: f32,
    reason_deferred: String,
    issue_number: Option<u32>,
}

enum Priority {
    Low,
    Medium,
    High,
    Critical,
}

enum Impact {
    Performance,     // Ralentit l'app
    Maintainability, // Rend code difficile √† maintenir
    Security,        // Risque s√©curit√©
    Reliability,     // Peut causer bugs
    Developer,       // Ralentit d√©veloppement
}

// Auto-g√©n√©ration de TECH_DEBT.md
fn generate_tech_debt_report(debts: &[TechDebt]) -> String {
    let mut md = String::from("# Dette Technique\n\n");
    
    // Grouper par priorit√©
    md.push_str("## üî¥ Critical\n\n");
    for debt in debts.iter().filter(|d| matches!(d.priority, Priority::Critical)) {
        md.push_str(&format!(
            "- [ ] **[#{}]** {} ({})\n  File: `{}:{}`\n  Impact: {:?}\n  Estim√©: {}h\n\n",
            debt.id, debt.description, debt.reason_deferred,
            debt.file.display(), debt.line, debt.impact, debt.estimated_hours
        ));
    }
    
    // ... similaire pour High, Medium, Low
    
    md
}
```

### Cr√©ation Automatique d'Issues GitHub

```rust
// Quand l'IA d√©tecte dette technique significative
fn should_create_github_issue(violation: &CodeViolation) -> bool {
    match violation {
        CodeViolation::FileTooLarge { lines, .. } if *lines > 280 => true,
        CodeViolation::CoverageLow { coverage } if *coverage < 75.0 => true,
        CodeViolation::HighComplexity { cyclomatic } if *cyclomatic > 15 => true,
        CodeViolation::SecurityVulnerability { severity } => 
            matches!(severity, Severity::High | Severity::Critical),
        _ => false,
    }
}

async fn create_github_issue(violation: CodeViolation) -> Result<Issue, Error> {
    let issue = match violation {
        CodeViolation::FileTooLarge { file, lines, max } => {
            Issue {
                title: format!("üèóÔ∏è Refactor: Split {} ({} lines)", file.display(), lines),
                body: format!(
                    "## Probl√®me\n\n\
                     Le fichier `{}` contient {} lignes (max: {}).\n\n\
                     ## Solution Propos√©e\n\n\
                     - Identifier responsabilit√©s distinctes\n\
                     - Extraire en sous-modules\n\
                     - Cr√©er mod.rs pour r√©exporter\n\n\
                     ## Estimation\n\n\
                     2-3 heures",
                    file.display(), lines, max
                ),
                labels: vec!["tech-debt".into(), "refactoring".into()],
                priority: "medium",
            }
        }
        // ... autres types de violations
    };
    
    github_client.create_issue(&issue).await
}
```

### M√©triques de Dette Technique

```rust
// Calculer score de dette technique
struct TechDebtMetrics {
    total_todos: u32,
    critical_items: u32,
    files_over_limit: u32,
    functions_over_50_lines: u32,
    coverage_below_80: bool,
    clippy_warnings: u32,
    security_vulnerabilities: u32,
    
    // Score global (0-100, 100 = z√©ro dette)
    health_score: f32,
}

impl TechDebtMetrics {
    fn calculate_health_score(&self) -> f32 {
        let mut score = 100.0;
        
        // P√©nalit√©s
        score -= self.total_todos as f32 * 0.5;
        score -= self.critical_items as f32 * 5.0;
        score -= self.files_over_limit as f32 * 10.0;
        score -= self.functions_over_50_lines as f32 * 1.0;
        score -= if self.coverage_below_80 { 15.0 } else { 0.0 };
        score -= self.clippy_warnings as f32 * 2.0;
        score -= self.security_vulnerabilities as f32 * 20.0;
        
        score.max(0.0).min(100.0)
    }
    
    fn get_grade(&self) -> &'static str {
        match self.health_score {
            90.0..=100.0 => "A (Excellent)",
            80.0..=89.9 => "B (Bon)",
            70.0..=79.9 => "C (Acceptable)",
            60.0..=69.9 => "D (√Ä am√©liorer)",
            _ => "F (Critique)",
        }
    }
}

// Rapport hebdomadaire
println!("üìä RAPPORT DE DETTE TECHNIQUE\n");
println!("Score de sant√©: {:.1}/100 ({})", metrics.health_score, metrics.get_grade());
println!("\nD√©tails:");
println!("  TODOs: {}", metrics.total_todos);
println!("  Items critiques: {}", metrics.critical_items);
println!("  Fichiers >300L: {}", metrics.files_over_limit);
println!("  Fonctions >50L: {}", metrics.functions_over_50_lines);
println!("  Coverage <80%: {}", if metrics.coverage_below_80 { "Oui ‚ö†Ô∏è" } else { "Non ‚úÖ" });
println!("  Clippy warnings: {}", metrics.clippy_warnings);
println!("  Vuln√©rabilit√©s: {}", metrics.security_vulnerabilities);
```

---

## üìä SYST√àME D'AUTO-√âVALUATION (IA)

## üß™ TESTS ET VALIDATION

### Structure de Tests

```rust
// tests/integration_test.rs
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_fetch_prices_success() {
        let service = DataService::new_mock();
        let result = service.fetch_prices("usd", 10, false).await;
        
        assert!(result.is_ok());
        let (prices, metadata) = result.unwrap();
        assert_eq!(prices.len(), 10);
        assert_eq!(metadata.source, DataSource::Api);
    }
    
    #[tokio::test]
    async fn test_fetch_prices_cache_fallback() {
        let service = DataService::new_mock_with_api_error();
        
        // Pr√©-remplir le cache
        service.cache.set("crypto", "prices", &mock_prices()).unwrap();
        
        let result = service.fetch_prices("usd", 10, true).await;
        
        assert!(result.is_ok());
        let (_, metadata) = result.unwrap();
        assert_eq!(metadata.source, DataSource::Cache);
    }
    
    #[tokio::test]
    async fn test_fetch_prices_error() {
        let service = DataService::new_mock_with_api_error();
        let result = service.fetch_prices("usd", 10, false).await;
        
        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), ServiceError::ApiError(_)));
    }
}
```

### Couverture Obligatoire

```toml
# Cargo.toml
[profile.test]
opt-level = 0

# Lancer tests avec couverture
# cargo install cargo-tarpaulin
# cargo tarpaulin --out Html --output-dir coverage

# R√àGLE: Minimum 80% de couverture
```

---

## üé® STANDARDS DE CODE (RUST)

### Nommage

| Entit√© | Convention | Exemple | ‚ùå Non-autoris√© |
|--------|-----------|---------|----------------|
| Fichiers | snake_case | data_service.rs | DataService.rs |
| Modules | snake_case | api_client | apiClient |
| Structs | PascalCase | CryptoPrice | cryptoPrice |
| Enums | PascalCase | DataSource | dataSource |
| Fonctions | snake_case | fetch_prices | fetchPrices |
| Variables | snake_case | api_key | apiKey |
| Constants | UPPER_SNAKE | API_TIMEOUT | ApiTimeout |
| Lifetimes | 'a, 'b | &'a str | 'lifetime |

### Formatage (rustfmt)

```toml
# rustfmt.toml
max_width = 100
hard_tabs = false
tab_spaces = 4
newline_style = "Unix"
use_small_heuristics = "Default"
reorder_imports = true
reorder_modules = true
remove_nested_parens = true
edition = "2021"
```

### Clippy (Linter Strict)

```toml
# .clippy.toml
[clippy]
# Niveau de warning strict
warn-on-all-wildcard-imports = true

# Dans Cargo.toml
[lints.clippy]
all = "warn"
pedantic = "warn"
nursery = "warn"
cargo = "warn"

# Interdictions sp√©cifiques
unwrap_used = "deny"
expect_used = "warn"
panic = "deny"
todo = "warn"
unimplemented = "deny"
```

---

## üîÑ GESTION DES VERSIONS (GIT)

### Convention de Commits

```
feat: ajoute service de cache centralis√©
fix: corrige race condition dans api_client
docs: update README avec instructions Tauri
style: format code avec rustfmt
refactor: simplifie structure du cache
test: ajoute tests pour data_service
chore: update dependencies
perf: optimise serialization avec bincode
```

### Pre-commit Hooks

```bash
#!/bin/bash
# .git/hooks/pre-commit

# Format
cargo fmt -- --check || exit 1

# Lint
cargo clippy -- -D warnings || exit 1

# Tests
cargo test || exit 1

# Audit s√©curit√©
cargo audit || exit 1

echo "‚úÖ Pre-commit checks passed"
```

---

## ‚ö° PERFORMANCE (RUST-SPECIFIC)

### Optimisations Obligatoires

```rust
// ‚úÖ BON: Utiliser r√©f√©rences au lieu de clone
pub fn process_data(data: &[CryptoPrice]) -> Result<Summary, ServiceError> {
    // Travaille sur r√©f√©rence
}

// ‚ùå MAUVAIS: Clone inutile
pub fn process_data(data: Vec<CryptoPrice>) -> Result<Summary, ServiceError> {
    // Clone forc√© √† chaque appel
}

// ‚úÖ BON: Utiliser iterators au lieu de boucles
let total: f64 = prices.iter()
    .map(|p| p.volume)
    .sum();

// ‚úÖ BON: Async pour I/O bound
#[tokio::main]
async fn main() {
    let (crypto, forex, news) = tokio::join!(
        fetch_crypto(),
        fetch_forex(),
        fetch_news(),
    );
}

// ‚úÖ BON: Utiliser Cow pour √©viter clones
use std::borrow::Cow;

pub fn format_symbol<'a>(symbol: &'a str) -> Cow<'a, str> {
    if symbol.starts_with("BTC") {
        Cow::Borrowed(symbol)  // Pas de clone
    } else {
        Cow::Owned(format!("{}USD", symbol))  // Clone seulement si besoin
    }
}
```

### Profile de Build

```toml
# Cargo.toml

[profile.dev]
opt-level = 0
debug = true

[profile.release]
opt-level = 3
lto = "fat"              # Link-time optimization
codegen-units = 1        # Meilleure optimisation
strip = true             # Strip symbols
panic = "abort"          # Pas d'unwinding
```

---

## üîß TAURI-SPECIFIC

### Hot-Reload / Auto-Refresh UI (OBLIGATOIRE EN D√âVELOPPEMENT)

```bash
# R√àGLE DE D√âVELOPPEMENT:
# Toujours utiliser le mode watch pour auto-reload de l'UI

# ‚ùå MAUVAIS - Red√©marrage manuel √† chaque modification
cargo tauri dev

# ‚úÖ BON - Auto-reload activ√© (watch mode)
cargo watch -x "tauri dev"

# OU utiliser le script de d√©veloppement optimis√©:
npm run dev          # Si configur√© dans package.json
# OU
./scripts/dev.sh     # Script personnalis√© avec watch

# Alternative avec cargo-watch
cargo install cargo-watch  # Installation si n√©cessaire
cargo watch -x "tauri dev" -w src -w src-tauri/src
```

### Configuration Auto-Reload

```toml
# Cargo.toml - Section pour optimiser le dev
[profile.dev]
opt-level = 1  # L√©g√®re optimisation pour meilleure r√©activit√©

# .cargo/config.toml (cr√©er si n'existe pas)
[build]
target-dir = "target"  # Cache build pour reload plus rapide

[target.x86_64-unknown-linux-gnu]
rustflags = ["-C", "link-arg=-fuse-ld=mold"]  # Linker rapide (si mold install√©)
```

### Quand Red√©marrer vs Hot-Reload

```markdown
HOT-RELOAD AUTOMATIQUE (Pas besoin de red√©marrer):
‚úÖ Modifications HTML/CSS/JS (frontend)
‚úÖ Modifications de fichiers statiques
‚úÖ Changements de styles
‚úÖ Mise √† jour de contenu

RED√âMARRAGE N√âCESSAIRE (Recompilation Rust):
üîÑ Modifications dans src-tauri/src/*.rs
üîÑ Ajout de nouvelles commandes Tauri
üîÑ Changements dans Cargo.toml (d√©pendances)
üîÑ Modifications de la configuration Tauri
üîÑ Changements dans tauri.conf.json

WORKFLOW INTELLIGENT:
1. Modification frontend ‚Üí UI se met √† jour automatiquement
2. Modification backend Rust ‚Üí cargo watch d√©tecte et recompile
3. L'UI se recharge automatiquement apr√®s recompilation
```

### Script de D√©veloppement Recommand√©

```bash
# scripts/dev.sh
#!/bin/bash
# Script de d√©veloppement avec hot-reload optimal

echo "üöÄ D√©marrage mode d√©veloppement avec hot-reload..."

# V√©rifier si cargo-watch est install√©
if ! command -v cargo-watch &> /dev/null; then
    echo "üì¶ Installation de cargo-watch..."
    cargo install cargo-watch
fi

# Lancer en mode watch avec options optimales
cargo watch \
    -x "tauri dev" \
    -w src-tauri/src \
    -w src \
    -i "target/*" \
    -i "node_modules/*" \
    --clear \
    --notify

# Options:
# -x "tauri dev" : Commande √† ex√©cuter
# -w : Dossiers √† surveiller
# -i : Dossiers √† ignorer
# --clear : Clear console √† chaque rebuild
# --notify : Notifications syst√®me
```

### Configuration package.json (Si Frontend Node/NPM)

```json
{
  "scripts": {
    "dev": "cargo watch -x 'tauri dev'",
    "dev:ui": "vite",
    "dev:full": "concurrently \"npm run dev:ui\" \"cargo watch -x 'tauri dev'\""
  },
  "devDependencies": {
    "concurrently": "^8.0.0"
  }
}
```

### Optimisations pour Fedora

```bash
# Installation des outils recommand√©s sur Fedora
sudo dnf install -y \
    cargo-watch \
    mold \
    webkit2gtk4.0-devel \
    gtk3-devel

# Configuration du linker rapide (mold) pour Fedora
# ~/.cargo/config.toml
[target.x86_64-unknown-linux-gnu]
rustflags = ["-C", "link-arg=-fuse-ld=mold"]

# Cela acc√©l√®re la recompilation de 30-50%
```

### R√®gle pour l'IA

```markdown
LORS DU D√âVELOPPEMENT UI TAURI:

1. ‚úÖ TOUJOURS sugg√©rer d'utiliser cargo watch
2. ‚úÖ TOUJOURS mentionner le hot-reload si modifications frontend
3. ‚úÖ INDIQUER si recompilation Rust n√©cessaire
4. ‚úÖ PROPOSER script dev.sh si pas encore cr√©√©

MESSAGES TYPES:

Si modification frontend:
"‚úÖ Modification frontend effectu√©e. L'UI devrait se mettre √† jour automatiquement."

Si modification backend Rust:
"üîÑ Modification backend Rust. Si vous utilisez `cargo watch -x 'tauri dev'`, 
la recompilation et le reload se feront automatiquement. Sinon, red√©marrez l'app."

Si premi√®re fois:
"üí° Pour activer le hot-reload automatique, utilisez:
   cargo watch -x 'tauri dev'
   Cela √©vitera de red√©marrer manuellement l'UI √† chaque modification."
```

### Checklist Environnement de Dev

```markdown
[ ] cargo-watch install√© (cargo install cargo-watch)
[ ] Script dev.sh cr√©√© avec hot-reload
[ ] Configuration .cargo/config.toml optimis√©e
[ ] Linker rapide (mold) install√© sur Fedora
[ ] package.json avec script "dev" (si applicable)

COMMANDE DE D√âMARRAGE STANDARD:
$ cargo watch -x "tauri dev"

OU
$ ./scripts/dev.sh
```

---

### Commands Pattern

```rust
// commands/crypto.rs
use tauri::State;

#[tauri::command]
pub async fn fetch_crypto_prices(
    service: State<'_, Arc<DataService>>,
    vs_currency: String,
) -> Result<CryptoResponse, String> {
    service.fetch_prices(&vs_currency, 100, true)
        .await
        .map(|(prices, metadata)| CryptoResponse {
            prices,
            metadata,
        })
        .map_err(|e| e.to_string())
}

// Pas de logique m√©tier ici! Seulement bridge vers service
```

### State Management

```rust
// main.rs
use tauri::Manager;

fn main() {
    let data_service = Arc::new(DataService::new());
    let cache = Arc::new(CacheManager::new());
    
    tauri::Builder::default()
        .manage(data_service)
        .manage(cache)
        .invoke_handler(tauri::generate_handler![
            fetch_crypto_prices,
            save_settings,
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
```

---

## ‚úÖ PROCESSUS DE D√âVELOPPEMENT STRICT

### Workflow Obligatoire

```
1. PLANNING (5-10 min)
   - D√©finir responsabilit√© du module (1 phrase)
   - Estimer taille finale
   - Si >300L ‚Üí Design split FIRST
   - Identifier d√©pendances (niveau DAG)

2. CODING (TDD)
   - √âcrire test d'abord
   - Impl√©menter minimum pour passer test
   - Refactor si n√©cessaire
   - V√©rifier taille tous les 50 lignes

3. AUDIT AVANT COMMIT (OBLIGATOIRE)
   cargo fmt
   cargo clippy
   cargo test
   cargo audit
   
   Si FAIL ‚Üí FIX puis retry
   Si PASS ‚Üí commit autoris√©

4. COMMIT
   - Format: type: description
   - Atomique (1 feature/fix par commit)
   - Message clair en fran√ßais

5. MONTHLY AUDIT
   cargo outdated
   cargo tree (v√©rifier deps)
   cargo bloat --release (v√©rifier taille binaire)
```

---

## üö´ INTERDICTIONS ABSOLUES

```
‚ùå JAMAIS:
  1. unwrap() sans expect() avec message
  2. panic!() dans production code
  3. Clone() sans justification
  4. pub sur tout (minimiser surface API)
  5. Ignorer warnings Clippy
  6. Code comment√© >5 lignes
  7. TODO sans issue GitHub li√©e
  8. Hardcoded paths (utiliser Tauri path API)
  9. Donn√©es mock en production
  10. Import circulaire
  11. >300 lignes par fichier service
  12. Tests avec expect("TODO")
  13. Unsafe sans SAFETY comment
  14. D√©pendances non audit√©es
  15. Credentials en dur
  16. Commiter le code (git commit/push) - UNIQUEMENT sur demande explicite
  17. Cr√©er fichiers .md/.txt de documentation - UNIQUEMENT sur demande explicite
```

---

## üîí R√àGLES GIT - SIMPLE ET CLAIR

### Ne JAMAIS Commiter Automatiquement

```markdown
R√àGLE ABSOLUE:
‚ùå L'IA ne fait JAMAIS de git commit
‚ùå L'IA ne fait JAMAIS de git push
‚ùå L'IA ne fait JAMAIS de git add

POURQUOI:
- Les commits doivent √™tre faits apr√®s impl√©mentations importantes finalis√©es
- L'utilisateur d√©cide QUAND commiter
- Pas de temps perdu avec commits syst√©matiques

QUAND COMMITER:
‚úÖ UNIQUEMENT quand l'utilisateur demande explicitement:
   "Commite ces changements"
   "Fais un commit"
   "git commit"
   "Sauvegarde le travail"

L'IA CODE ‚Üí L'utilisateur COMMITE (quand il veut)
```

### Comportement de l'IA

```rust
// ‚ùå INTERDIT - Ne JAMAIS faire √ßa
fn after_task_completion() {
    run_command("git add .");
    run_command("git commit -m 'feat: ...'");
    run_command("git push");
}

// ‚úÖ BON - L'IA se concentre sur le code
fn after_task_completion() {
    // V√©rifier que le code est bon
    validate_code();
    run_tests();
    
    // C'est tout. Pas de git.
    // L'utilisateur commitera quand il voudra.
}

// ‚úÖ BON - Seulement si demand√© explicitement
fn when_user_asks_to_commit(message: &str) {
    // Seulement si user dit "commite" ou "git commit"
    run_command(&format!("git add ."));
    run_command(&format!("git commit -m '{}'", message));
}
```

---

## üìÑ R√àGLES CR√âATION FICHIERS - SIMPLE ET CLAIR

### Ne JAMAIS Cr√©er de Fichiers Documentation Automatiquement

```markdown
R√àGLE ABSOLUE:
‚ùå L'IA ne cr√©e JAMAIS de fichiers .md ou .txt automatiquement
‚ùå Pas de README.md, CHANGELOG.md, TODO.txt, NOTES.md, etc.

POURQUOI:
- Ces fichiers encombrent le projet
- L'utilisateur d√©cide s'il en a besoin
- Pas de fichiers inutiles cr√©√©s

EXCEPTIONS (cr√©ation automatique OK):
‚úÖ Fichiers de CODE: .rs, .toml, .json, .sql
‚úÖ Fichiers de CONFIG: Cargo.toml, .gitignore, rustfmt.toml
‚úÖ Fichiers de TESTS: dans /tests

QUAND CR√âER .md/.txt:
‚úÖ UNIQUEMENT quand l'utilisateur demande explicitement:
   "Cr√©e un README"
   "Fais un fichier TODO.md"
   "Documente l'architecture dans ARCHITECTURE.md"

L'IA CODE ‚Üí Pas de documentation automatique
```

### Comportement de l'IA

```rust
// ‚ùå INTERDIT
fn after_complex_feature() {
    create_file("README.md", "# Documentation...");      // NON!
    create_file("ARCHITECTURE.md", "# Archi...");        // NON!
    create_file("TODO.txt", "Things to do...");          // NON!
}

// ‚úÖ BON - Cr√©er seulement le code
fn implement_feature() {
    create_file("src/services/my_service.rs", code);     // OK
    create_file("tests/test_service.rs", tests);         // OK
    create_file("src/models/data.rs", models);           // OK
    
    // Pas de README, pas de docs, juste le code.
}

// ‚úÖ BON - Seulement si demand√©
fn when_user_asks_for_readme() {
    // Seulement si user dit "cr√©e un README"
    create_file("README.md", content);
}
```

---

## ‚ö†Ô∏è RAPPEL SIMPLE POUR L'IA

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  APR√àS AVOIR COD√â:                                      ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚úÖ V√©rifier que √ßa compile (cargo build)              ‚îÇ
‚îÇ  ‚úÖ V√©rifier les tests (cargo test)                    ‚îÇ
‚îÇ  ‚úÖ V√©rifier clippy (cargo clippy)                     ‚îÇ
‚îÇ  ‚úÖ Formatter (cargo fmt)                              ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚ùå PAS de git commit                                  ‚îÇ
‚îÇ  ‚ùå PAS de cr√©ation de README/CHANGELOG/TODO           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  L'utilisateur commitera quand IL voudra.              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä M√âTRIQUES DE QUALIT√â

### Build Validation Checklist

```bash
---

## üìä SYST√àME D'AUTO-√âVALUATION (IA)

### M√©triques de Succ√®s par T√¢che

```rust
// L'IA √©value chaque t√¢che avec ces m√©triques
struct TaskMetrics {
    task_id: String,
    task_type: TaskType,
    started_at: DateTime,
    completed_at: DateTime,
    
    // Conformit√© aux r√®gles
    rules_followed: u32,
    rules_violated: u32,
    violations: Vec<RuleViolation>,
    
    // Qualit√© du code
    tests_written: u32,
    coverage_before: f32,
    coverage_after: f32,
    coverage_delta: f32,
    
    // Validation
    clippy_warnings_before: u32,
    clippy_warnings_after: u32,
    build_success: bool,
    tests_passing: bool,
    
    // Performance
    build_time_ms: u64,
    test_time_ms: u64,
    binary_size_delta_kb: i64,
    
    // M√©triques code
    lines_added: u32,
    lines_removed: u32,
    files_modified: u32,
    files_created: u32,
    
    // Score final
    quality_score: f32,  // 0-100
    success: bool,
}

enum TaskType {
    NewFeature,
    BugFix,
    Refactoring,
    Documentation,
    Testing,
    Optimization,
}

// Calcul du score de qualit√©
impl TaskMetrics {
    fn calculate_quality_score(&self) -> f32 {
        let mut score = 100.0;
        
        // P√©nalit√©s
        score -= self.rules_violated as f32 * 10.0;  // -10 par violation
        score -= self.clippy_warnings_after as f32 * 5.0;  // -5 par warning
        score -= if !self.build_success { 50.0 } else { 0.0 };
        score -= if !self.tests_passing { 40.0 } else { 0.0 };
        score -= if self.coverage_delta < 0.0 { 15.0 } else { 0.0 };  // Coverage baisse
        
        // Bonus
        score += (self.tests_written as f32 * 2.0).min(10.0);  // +2 par test (max +10)
        score += if self.coverage_after > 85.0 { 5.0 } else { 0.0 };
        
        score.max(0.0).min(100.0)
    }
}
```

### Rapport Automatique Apr√®s Chaque T√¢che

```rust
fn generate_task_report(metrics: &TaskMetrics) {
    println!("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó");
    println!("‚ïë              üìä RAPPORT D'AUTO-√âVALUATION                    ‚ïë");
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë T√¢che: {:<54} ‚ïë", truncate(&metrics.task_id, 54));
    println!("‚ïë Type:  {:<54} ‚ïë", format!("{:?}", metrics.task_type));
    println!("‚ïë Dur√©e: {:<54} ‚ïë", format_duration(metrics.started_at, metrics.completed_at));
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë CONFORMIT√â                                                    ‚ïë");
    println!("‚ïë   R√®gles respect√©es:  {:<41} ‚ïë", metrics.rules_followed);
    println!("‚ïë   R√®gles viol√©es:     {:<41} ‚ïë", metrics.rules_violated);
    
    if !metrics.violations.is_empty() {
        println!("‚ïë   Violations:                                                 ‚ïë");
        for v in &metrics.violations {
            println!("‚ïë     ‚Ä¢ {:<55} ‚ïë", v.description);
        }
    }
    
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë QUALIT√â                                                       ‚ïë");
    println!("‚ïë   Tests √©crits:       {:<41} ‚ïë", metrics.tests_written);
    println!("‚ïë   Coverage:           {:<41} ‚ïë", 
        format!("{:.1}% ‚Üí {:.1}% ({:+.1}%)", 
            metrics.coverage_before, 
            metrics.coverage_after, 
            metrics.coverage_delta)
    );
    println!("‚ïë   Clippy warnings:    {:<41} ‚ïë", 
        format!("{} ‚Üí {}", metrics.clippy_warnings_before, metrics.clippy_warnings_after)
    );
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë VALIDATION                                                    ‚ïë");
    println!("‚ïë   Build:              {:<41} ‚ïë", status_icon(metrics.build_success));
    println!("‚ïë   Tests:              {:<41} ‚ïë", status_icon(metrics.tests_passing));
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë PERFORMANCE                                                   ‚ïë");
    println!("‚ïë   Build time:         {:<41} ‚ïë", format!("{} ms", metrics.build_time_ms));
    println!("‚ïë   Test time:          {:<41} ‚ïë", format!("{} ms", metrics.test_time_ms));
    println!("‚ïë   Binary size delta:  {:<41} ‚ïë", format!("{:+} KB", metrics.binary_size_delta_kb));
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë CODE                                                          ‚ïë");
    println!("‚ïë   Lignes ajout√©es:    {:<41} ‚ïë", format!("+{}", metrics.lines_added));
    println!("‚ïë   Lignes supprim√©es:  {:<41} ‚ïë", format!("-{}", metrics.lines_removed));
    println!("‚ïë   Fichiers modifi√©s:  {:<41} ‚ïë", metrics.files_modified);
    println!("‚ïë   Fichiers cr√©√©s:     {:<41} ‚ïë", metrics.files_created);
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë SCORE DE QUALIT√â:     {:<41} ‚ïë", 
        format!("{:.1}/100 ({})", metrics.quality_score, get_grade(metrics.quality_score))
    );
    println!("‚ïë STATUT:               {:<41} ‚ïë", 
        if metrics.success { "‚úÖ SUCC√àS" } else { "‚ùå √âCHEC" }
    );
    println!("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù");
}

fn status_icon(success: bool) -> &'static str {
    if success { "‚úÖ Succ√®s" } else { "‚ùå √âchec" }
}

fn get_grade(score: f32) -> &'static str {
    match score {
        90.0..=100.0 => "A",
        80.0..=89.9 => "B",
        70.0..=79.9 => "C",
        60.0..=69.9 => "D",
        _ => "F",
    }
}
```

### Red Flags (Alertes Automatiques)

```rust
// L'IA doit alerter l'utilisateur si:
struct RedFlags {
    coverage_drop: bool,          // Coverage baisse >5%
    build_time_increase: bool,    // Build time +20%
    binary_size_increase: bool,   // Binary size +10MB
    many_files_modified: bool,    // >5 fichiers pour 1 feature
    commit_without_tests: bool,   // Commit sans tests
    violation_detected: bool,     // Violation de r√®gle
}

impl RedFlags {
    fn check(metrics: &TaskMetrics, baseline: &Baseline) -> Self {
        Self {
            coverage_drop: metrics.coverage_delta < -5.0,
            build_time_increase: 
                metrics.build_time_ms > baseline.build_time_ms * 12 / 10,  // +20%
            binary_size_increase: 
                metrics.binary_size_delta_kb > 10_000,  // +10MB
            many_files_modified: 
                metrics.files_modified > 5,
            commit_without_tests: 
                metrics.tests_written == 0 && matches!(metrics.task_type, TaskType::NewFeature),
            violation_detected: 
                metrics.rules_violated > 0,
        }
    }
    
    fn alert_user(&self) {
        if self.any_raised() {
            eprintln!("\n‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è RED FLAGS D√âTECT√âS ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n");
            
            if self.coverage_drop {
                eprintln!("üî¥ Coverage a baiss√© de >5%");
                eprintln!("   Action: Ajouter tests pour remonter");
            }
            
            if self.build_time_increase {
                eprintln!("üî¥ Build time a augment√© de >20%");
                eprintln!("   Action: Profiler et optimiser");
            }
            
            if self.binary_size_increase {
                eprintln!("üî¥ Binary size a augment√© de >10MB");
                eprintln!("   Action: cargo bloat --release");
            }
            
            if self.many_files_modified {
                eprintln!("üî¥ Trop de fichiers modifi√©s (>5)");
                eprintln!("   Action: Split en commits atomiques");
            }
            
            if self.commit_without_tests {
                eprintln!("üî¥ Nouvelle feature sans tests");
                eprintln!("   Action: √âcrire tests avant commit");
            }
            
            if self.violation_detected {
                eprintln!("üî¥ Violations de r√®gles d√©tect√©es");
                eprintln!("   Action: Corriger avant commit");
            }
            
            eprintln!("\n‚ö†Ô∏è DEMANDER REVIEW UTILISATEUR AVANT COMMIT");
        }
    }
    
    fn any_raised(&self) -> bool {
        self.coverage_drop 
            || self.build_time_increase 
            || self.binary_size_increase
            || self.many_files_modified
            || self.commit_without_tests
            || self.violation_detected
    }
}
```

### Historique des M√©triques

```rust
// Sauvegarder historique dans .ai_metrics.json
struct MetricsHistory {
    tasks: Vec<TaskMetrics>,
    baseline: Baseline,
    trends: Trends,
}

struct Baseline {
    build_time_ms: u64,
    test_time_ms: u64,
    binary_size_kb: u64,
    coverage: f32,
}

struct Trends {
    average_quality_score: f32,
    coverage_trend: TrendDirection,
    build_time_trend: TrendDirection,
    violation_rate: f32,
}

enum TrendDirection {
    Improving,
    Stable,
    Degrading,
}

// Rapport hebdomadaire
fn generate_weekly_report(history: &MetricsHistory) {
    println!("üìà RAPPORT HEBDOMADAIRE\n");
    println!("T√¢ches compl√©t√©es: {}", history.tasks.len());
    println!("Score moyen: {:.1}/100", history.trends.average_quality_score);
    println!("Coverage trend: {:?}", history.trends.coverage_trend);
    println!("Build time trend: {:?}", history.trends.build_time_trend);
    println!("Taux de violation: {:.1}%", history.trends.violation_rate * 100.0);
    
    println!("\nTop 3 T√¢ches (meilleurs scores):");
    let mut sorted = history.tasks.clone();
    sorted.sort_by(|a, b| b.quality_score.partial_cmp(&a.quality_score).unwrap());
    for (i, task) in sorted.iter().take(3).enumerate() {
        println!("  {}. {} - Score: {:.1}", i + 1, task.task_id, task.quality_score);
    }
    
    println!("\nAm√©lioration Continue:");
    if history.trends.coverage_trend == TrendDirection::Degrading {
        println!("  ‚ö†Ô∏è Coverage en baisse - Prioriser les tests");
    }
    if history.trends.build_time_trend == TrendDirection::Degrading {
        println!("  ‚ö†Ô∏è Build time en hausse - Investiguer");
    }
    if history.trends.violation_rate > 0.1 {
        println!("  ‚ö†Ô∏è Taux de violation √©lev√© - Revoir processus");
    }
}
```

### Auto-Critique Constructive

```rust
// L'IA analyse ses propres performances
fn self_critique(metrics: &TaskMetrics) -> Vec<Improvement> {
    let mut improvements = Vec::new();
    
    if metrics.tests_written < 3 {
        improvements.push(Improvement {
            area: "Testing".into(),
            issue: format!("Seulement {} tests √©crits", metrics.tests_written),
            suggestion: "Viser minimum 3 tests: success, error, edge case".into(),
        });
    }
    
    if metrics.coverage_delta < 0.0 {
        improvements.push(Improvement {
            area: "Coverage".into(),
            issue: format!("Coverage baiss√© de {:.1}%", metrics.coverage_delta),
            suggestion: "Ne jamais laisser baisser le coverage - Ajouter tests".into(),
        });
    }
    
    if metrics.files_modified > 5 {
        improvements.push(Improvement {
            area: "Atomicit√©".into(),
            issue: format!("{} fichiers modifi√©s", metrics.files_modified),
            suggestion: "Split en commits plus atomiques (1 feature = 1-3 fichiers)".into(),
        });
    }
    
    if !metrics.success {
        improvements.push(Improvement {
            area: "Process".into(),
            issue: "T√¢che √©chou√©e".into(),
            suggestion: "Suivre checklist pr√©-coding plus rigoureusement".into(),
        });
    }
    
    improvements
}

struct Improvement {
    area: String,
    issue: String,
    suggestion: String,
}
```

---

## üåê CONTEXTE PROJET (SP√âCIFIQUE √Ä CE PROJET)

### Variables d'Environnement Requises

```bash
# .env.example (cr√©er .env √† partir de ce template)

# API Keys (JAMAIS commiter les vraies valeurs!)
COINGECKO_API_KEY=your_api_key_here
BINANCE_API_KEY=your_api_key_here
BINANCE_API_SECRET=your_secret_here

# Configuration Application
RUST_LOG=info                    # debug | info | warn | error
APP_ENV=development              # development | production | testing
DATABASE_URL=./data/app.db       # Chemin vers SQLite

# Cache
CACHE_ENABLED=true
CACHE_TTL_CRYPTO=300             # 5 minutes
CACHE_TTL_FOREX=60               # 1 minute

# API Configuration
API_TIMEOUT_SECS=30
API_RATE_LIMIT_PER_MIN=60
```

### Stack Technique de ce Projet

```toml
# Informations pour l'IA sur le stack utilis√©

[project]
name = "analyses-historiques"
type = "desktop-app"
framework = "tauri"
language = "rust"
edition = "2021"

[frontend]
type = "minimal"  # HTML/CSS/JS l√©ger, pas de framework lourd
location = "src/"

[backend]
location = "src-tauri/"
primary_language = "rust"

[architecture]
pattern = "services"
layers = ["commands", "services", "models", "db", "utils"]
dag_enforcement = true

[data_sources]
primary_api = "CoinGecko"
fallback = "cache"
storage = "SQLite"

[constraints]
max_file_lines_services = 300
max_file_lines_main = 120
min_test_coverage = 80
zero_clippy_warnings = true
zero_mock_data = true
```

### Contraintes Sp√©cifiques du Projet

```rust
// Contraintes √† respecter ABSOLUMENT pour ce projet:

const PROJECT_CONSTRAINTS: &str = r#"
1. DONN√âES UNIQUEMENT R√âELLES
   - Pas de mock data en production
   - Toutes donn√©es depuis CoinGecko API ou cache
   - Gestion erreur explicite si API down

2. PERFORMANCE
   - D√©marrage app: <2s
   - Fetch crypto prices: <1s (avec cache)
   - UI doit rester responsive

3. OFFLINE-FIRST
   - App doit fonctionner sans internet (avec cache)
   - Alerter utilisateur si donn√©es obsol√®tes
   - Sync automatique quand connexion revenue

4. S√âCURIT√â
   - API keys chiffr√©es
   - Aucun secret en dur
   - Validation stricte des inputs

5. COMPATIBILIT√â
   - Linux (Ubuntu 22.04+)
   - Windows 10+
   - macOS 11+
"#;
```

### Commandes Sp√©cifiques au Projet

```bash
# Setup initial
./scripts/setup.sh               # Install d√©pendances + create DB

# D√©veloppement
cargo tauri dev                  # Lancer en mode dev
cargo watch -x "tauri dev"       # Auto-reload

# Tests
cargo test                       # Tests unitaires
cargo test --test integration    # Tests d'int√©gration
./scripts/test_coverage.sh       # Coverage report

# Build
cargo tauri build                # Build release (Linux/Windows/macOS)
./scripts/build_all_platforms.sh # Cross-compile toutes plateformes

# Maintenance
./scripts/update_deps.sh         # Update dependencies
./scripts/audit.sh               # Security audit
./scripts/cleanup.sh             # Clean build artifacts
```

---

## üìä M√âTRIQUES DE QUALIT√â

### Build Validation Checklist

```bash
‚úì cargo build --release        # 0 errors, 0 warnings
‚úì cargo clippy -- -D warnings   # 0 warnings
‚úì cargo test                    # 100% tests pass
‚úì cargo tarpaulin              # >80% coverage
‚úì cargo audit                   # 0 vulnerabilities
‚úì cargo bloat --release        # Binary size acceptable
‚úì cargo outdated               # Dependencies up-to-date
```

### M√©triques Continues

```
- Taille binaire release: <50MB
- Temps de d√©marrage: <2s
- Utilisation m√©moire: <200MB idle
- Tests coverage: >80%
- Clippy warnings: 0
- Cargo audit issues: 0
- Code mort (dead_code): 0
- Fichiers >300L: 0
```

---

## üìö D√âPENDANCES RECOMMAND√âES (VERSIONS √Ä JOUR 2025)

```toml
[dependencies]
# Tauri (Version 2.0 - Stable depuis 2024)
tauri = { version = "2.0", features = ["shell-open", "protocol-asset"] }
tauri-plugin-store = "2.0"       # State persistence
tauri-plugin-window = "2.0"      # Window management

# Async runtime
tokio = { version = "1.40", features = ["full", "tracing"] }

# HTTP client
reqwest = { version = "0.12", features = ["json", "gzip", "brotli"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"  # Plus rapide que JSON pour cache

# Error handling
thiserror = "1.0"
anyhow = "1.0"
color-eyre = "0.6"  # Meilleurs messages d'erreur en dev

# Database
diesel = { version = "2.2", features = ["sqlite", "r2d2", "returning_clauses_for_sqlite_3_35"] }
diesel_migrations = "2.2"
r2d2 = "0.8"  # Connection pooling

# Validation
validator = { version = "0.18", features = ["derive"] }

# Logging & Tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }
tracing-appender = "0.2"  # Log rotation

# Date & Time
chrono = { version = "0.4", features = ["serde"] }

# Crypto & Security
aes-gcm = "0.10"
argon2 = "0.5"  # Password hashing
sha2 = "0.10"

# Configuration
config = "0.14"
dotenvy = "0.15"  # .env file loading

# Testing
mockall = "0.13"
wiremock = "0.6"  # HTTP mocking pour tests

# Utilities
itertools = "0.13"
rayon = "1.10"  # Parall√©lisme facile
dashmap = "6.0"  # Concurrent HashMap

[dev-dependencies]
cargo-tarpaulin = "0.31"
criterion = "0.5"  # Benchmarking
proptest = "1.5"   # Property-based testing
rstest = "0.22"    # Fixtures pour tests

[build-dependencies]
tauri-build = "2.0"

# Profile optimis√© pour release
[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
strip = true
panic = "abort"

# Profile pour dev avec meilleures perfs
[profile.dev]
opt-level = 1  # Un peu d'optimisation pour dev plus fluide

# Profile pour tests rapides
[profile.test]
opt-level = 1
```

### Notes sur les Versions

```markdown
# CHANGELOG DES VERSIONS MAJEURES

## Tauri 1.x ‚Üí 2.0 (2024)
- Architecture mobile am√©lior√©e
- Meilleure s√©curit√© IPC
- Plugins syst√®me redesign√©s
- BREAKING: APIs chang√©es, migration n√©cessaire

## Diesel 2.1 ‚Üí 2.2 (2024)
- Support SQLite 3.35+ requis
- Returning clauses pour SQLite
- Meilleures performances

## Validator 0.16 ‚Üí 0.18 (2024)
- Custom validators am√©lior√©s
- Meilleurs messages d'erreur

## Reqwest 0.11 ‚Üí 0.12 (2024)
- HTTP/3 support
- Compression brotli native
```

---

**Version du Guide** : 2.0 (Rust + Tauri 2.0)  
**Derni√®re mise √† jour** : 31 octobre 2025  
**Stack** : Rust 2021 Edition + Tauri 2.0 + SQLite  
**Auteur** : Guide pour Agent IA de codage  
**Licence** : Usage interne projet

---

## üéì AIDE-M√âMOIRE RAPIDE POUR L'IA

### Checklist 5 Secondes Avant Chaque Action

```
‚úì J'ai lu COMPL√àTEMENT les fichiers concern√©s?
‚úì Architecture DAG respect√©e (pas d'import circulaire)?
‚úì Fichier restera <300 lignes apr√®s modification?
‚úì Je vais √©crire les TESTS D'ABORD (TDD)?
‚úì ZERO mock data (seulement vraies donn√©es)?
```

### R√©flexes Automatiques

| Si je vois... | Je fais... |
|---------------|------------|
| `unwrap()` | Remplacer par `?` ou `expect("msg")` |
| Mock data | REJETER + Sugg√©rer API/DB |
| >280 lignes | WARN utilisateur |
| >300 lignes | STOP + Demander split |
| Test √©choue | FIX avant tout |
| Clippy warning | FIX imm√©diatement |
| Import circulaire | BLOQUER + Extraire |
| Magic number | Extraire en constante |
| Fonction >50L | Proposer split |
| Clone >5x | Sugg√©rer r√©f√©rences |

### Questions √† me Poser

1. **Est-ce que j'utilise des vraies donn√©es?** (Z√âRO mock tol√©r√©)
2. **Est-ce que j'ai √©crit le test AVANT le code?** (TDD obligatoire)
3. **Est-ce que le fichier reste <300 lignes?** (Split si non)
4. **Est-ce que je g√®re TOUTES les erreurs?** (Result<>, pas de panic!)
5. **Est-ce que cargo clippy est content?** (0 warnings obligatoire)

### En Cas de Doute

```
SI INCERTAIN ‚Üí DEMANDER √† l'utilisateur
SI CERTAIN ‚Üí APPLIQUER conventions Rust
SI VIOLATION D√âTECT√âE ‚Üí BLOQUER imm√©diatement
```

---

## üìû CONTACT & SUPPORT

**Pour questions sur ce guide:**
- Cr√©er une issue GitHub avec label `clinerules-question`
- Format: `[R√àGLE] Question sur le principe X`

**Pour proposer am√©liorations:**
- Pull request avec modifications du `.clinerules`
- Expliquer le probl√®me r√©solu et la solution

**R√©visions du guide:**
- Review mensuel obligatoire
- Update si nouvelles best practices Rust
- Adaptation selon feedback √©quipe

---

**ü§ñ MESSAGE FINAL POUR L'IA:**

```
Ce guide est ton manuel d'op√©ration absolu.
Chaque r√®gle existe pour une raison (qualit√©, maintenabilit√©, s√©curit√©).

Suis-le rigoureusement mais reste pragmatique:
- Applique les r√®gles STRICTES en production
- Sois FLEXIBLE pour prototypes/tests
- DEMANDE clarification si ambigu√Øt√©
- AUTO-√âVALUE apr√®s chaque t√¢che
- AM√âLIORE-TOI continuellement

Objectif final: Code professionnel, sans dette technique, maintenable sur 5+ ans.

Bonne chance! üöÄ
```